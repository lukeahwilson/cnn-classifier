{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25b39c95",
   "metadata": {},
   "source": [
    "# CNN CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f3e0cd",
   "metadata": {},
   "source": [
    "PURPOSE:\n",
    "  - API to train and apply leveraged pretrained vision models for classification\n",
    "  \n",
    "REQUIREMENTS:\n",
    "  - Pretained model is downloaded and can be trained on a dataset by user\n",
    "  - The number of attached fully connected layers is customizable by the user\n",
    "  - The deeper convolutional layers are unfrozen for a period of time during training for tuning\n",
    "  - User can load a model and continue training or move directly to inference\n",
    "  - Saved trained model information is stored in a specific folder with a useful naming convention\n",
    "  - There are time-limited prompts that allow the user to direct processes as needed\n",
    "  - Training performance can be tested before moving onward to inference if desired\n",
    "  - Predictions are made using paralleled batches and are saved in a results dictionary\n",
    "  \n",
    "HOW TO USE:\n",
    "  - If no model has been trained and saved, start by training a model\n",
    "  - Store data in folders at this location: os.path.expanduser('~') + '/Programming Data/'\n",
    "  - For training, 'train' and 'valid' folders with data are required in the data_dir\n",
    "  - For overfit testing, an 'overfit' folder with data is required in the data_dir\n",
    "  - For performance testing, a 'test' folder with data is required in the data_dir\n",
    "  - For inference, put data of interest in a 'predict' folder in the data_dir\n",
    "  - For saving and loading models, create a 'models' folder in the data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01c54a2",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "164be129",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os, random\n",
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch import nn, optim\n",
    "from PIL import Image\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24ac01c",
   "metadata": {},
   "source": [
    "## Define Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6ec94d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ArgParse Not Used in Notebooks\n",
    "\n",
    "def u1_get_input_args(): \n",
    "    Purpose:\n",
    "        - Creates and stores command line arguments inputted by the user.\n",
    "        - Attaches default arguments and help text to aid user.\n",
    "    Command Line Arguments:\n",
    "        1. Data directory as --dir\n",
    "        2. Choose to load model as --load\n",
    "        3. Choose to train model as --train\n",
    "        4. Define number of training epochs as --epoch\n",
    "        5. Define network number of hidden layers --layer\n",
    "        6. Define learnrate as --learn\n",
    "        7. Choose pretrained CNN model as --model\n",
    "    Returns:\n",
    "        - Stored command line arguments as an Argument Parser Object with parse_args() data structure\n",
    "'''\n",
    "\n",
    "argdir = 'Flower_data'\n",
    "argload = 'n'\n",
    "argtrain = 'n'\n",
    "argepoch = 50\n",
    "arglayer = 2\n",
    "arglearn = 0.003\n",
    "argmodel = 'googlenet' # 'vgg', 'alexnet', 'googlenet', 'densenet', 'inception', 'resnext', 'shufflenet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0f2084",
   "metadata": {},
   "source": [
    "## Import Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b7ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cnn_utility_functions import *\n",
    "\n",
    "def u2_load_processed_data(data_dir):\n",
    "    '''\n",
    "    Purpose:\n",
    "        - Access data directory and produce a dictionary of datasets\n",
    "        - Create a dictionary of the class labels and read in the data labels\n",
    "    Parameters:\n",
    "        - data_dir = pathway to the data\n",
    "    Returns:\n",
    "        - dictionary of datasets\n",
    "        - dictionary of data labels\n",
    "        - dictionary of class labels\n",
    "    '''\n",
    "    # Initialize empty dictionaries to hold data and data labels\n",
    "    dict_datasets = {}\n",
    "    dict_data_labels = {}\n",
    "\n",
    "    # Iterate through folders in the data directory\n",
    "    for folder in os.listdir(data_dir):\n",
    "\n",
    "        # If data exists, create datasets for overfitting, testing, training, and validating data\n",
    "        if folder in ['overfit', 'test', 'train', 'valid']:\n",
    "            dict_datasets[folder + '_data'] = datasets.ImageFolder(data_dir + folder, transform=u3_process_data(folder))\n",
    "\n",
    "        # If data for inference exists, create a dataset from the predict folder\n",
    "        if folder == 'predict':\n",
    "            predict_transform = u3_process_data(folder)\n",
    "            dict_datasets['predict_data'] = [(predict_transform(Image.open(data_dir + folder + '/' + filename)),\n",
    "                            filename) for filename in os.listdir(data_dir + folder)]\n",
    "\n",
    "        # If a data names are added to the data directory as a json, open it and read into data label dictionary\n",
    "        if os.path.splitext(folder)[1] == '.json':\n",
    "            with open(data_dir + folder, 'r') as f:\n",
    "                dict_data_labels = json.load(f)\n",
    "\n",
    "    # Create a dictionary connecting class indexes to class labels, return the datasets and label dictionaries\n",
    "    dict_class_labels = {value : key for (key, value) in dict_datasets['train_data'].class_to_idx.items()}\n",
    "    return dict_datasets, dict_data_labels, dict_class_labels\n",
    "\n",
    "\n",
    "def u3_process_data(transform_request):\n",
    "    '''\n",
    "    Purpose:\n",
    "        - Define an assortment of transforms for application to specific datasets\n",
    "        - Return the appropriate transformation that corresponds to the inputted request\n",
    "        - Defined transforms are composed of a sequence of individual transform operations\n",
    "        - Depending on the needs of each data set, a transform will use specific operations\n",
    "    Parameters:\n",
    "        - transformation_request = selected transformation type\n",
    "    Returns:\n",
    "        - transform that corresponds to the request\n",
    "    '''\n",
    "    image_1d_size = 224\n",
    "\n",
    "    predict_transform = transforms.Compose([transforms.Resize(int(np.round_(image_1d_size*1.1, decimals=0))),\n",
    "                                            transforms.CenterCrop(image_1d_size),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    inverse_transform = transforms.Compose([transforms.Normalize([0, 0, 0], [1/0.229, 1/0.224, 1/0.225]),\n",
    "                                            transforms.Normalize([-0.485, -0.456, -0.406], [1, 1, 1])])\n",
    "\n",
    "    train_transform = transforms.Compose([transforms.RandomRotation(20),\n",
    "                                          transforms.RandomResizedCrop(image_1d_size),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "\n",
    "    valid_transform = transforms.Compose([transforms.Resize(int(np.round_(image_1d_size*1.1, decimals=0))),\n",
    "                                          transforms.CenterCrop(image_1d_size),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    test_transform = transforms.Compose([transforms.Resize(int(np.round_(image_1d_size*1.1, decimals=0))),\n",
    "                                         transforms.CenterCrop(image_1d_size),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    game_transform = transforms.Compose([transforms.Resize(int(np.round_(image_1d_size*1.1, decimals=0))),\n",
    "                                         transforms.CenterCrop(image_1d_size),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    overfit_transform = train_transform\n",
    "    return locals()[transform_request + '_transform']\n",
    "\n",
    "\n",
    "def u4_data_iterator(dict_datasets):\n",
    "    '''\n",
    "    Purpose:\n",
    "        - Receive a dictionary of datasets\n",
    "        - Convert each dataset to a dataLoader\n",
    "        - Return a dictionary of dataloaders\n",
    "    Parameters:\n",
    "        - dict_datasets = dictionary of datasets\n",
    "    Returns:\n",
    "        - dict_data_loaders = dictionary of dataloaders\n",
    "    '''\n",
    "    dict_data_loaders = {}\n",
    "    for dataset in dict_datasets:\n",
    "        loader_type = dataset.split('_')[0] + '_loader'\n",
    "        dict_data_loaders[loader_type] = torch.utils.data.DataLoader(dict_datasets[dataset], batch_size=128, shuffle=True)\n",
    "    return dict_data_loaders\n",
    "\n",
    "\n",
    "def u5_time_limited_input(prompt, default=True):\n",
    "    '''\n",
    "    Purpose:\n",
    "        - Receive text and start a thread to initiate a user input prompt with that text\n",
    "        - Track thread time and limit time to an established TIMEOUT limit\n",
    "        - Return user input or after the TIMEOUT limit is reached return the default choice\n",
    "    Parameters:\n",
    "        - prompt = specific question text for display\n",
    "        - default = default choice if no user input is provided\n",
    "    Returns:\n",
    "        - choice = the user input or the default\n",
    "    '''\n",
    "    TIMEOUT = 10\n",
    "    prompt = prompt + f': \\'y\\' for yes, \\'n\\' for no ({TIMEOUT} seconds to choose): '\n",
    "    user_input_thread = Thread(target=u6_user_input_prompt, args=(prompt, default), daemon = True)\n",
    "    user_input_thread.start() # Start the thread, calling the user input function\n",
    "    user_input_thread.join(TIMEOUT) # Limit the thread to the TIMEOUT time limit\n",
    "    if not answered:\n",
    "        print('\\n No valid input, proceeding with operation...')\n",
    "    return choice\n",
    "\n",
    "\n",
    "def u6_user_input_prompt(prompt, default):\n",
    "    '''\n",
    "    Purpose:\n",
    "        - Receive a prompt and use it for user input prompting\n",
    "        - Once answered return True or False if input is yes or no\n",
    "        - Ask question again if the input is incorrect\n",
    "    Parameters:\n",
    "        - prompt = complete user input question text for display\n",
    "        - default = default choice if no user input is provided\n",
    "    Returns:\n",
    "        - choice = the user input or the default\n",
    "    '''\n",
    "    global choice, answered # Global variables are required to communicate input statuses back to the thread manager\n",
    "    choice = default\n",
    "    answered = False\n",
    "    while not answered:\n",
    "        choice = input(prompt)\n",
    "        if choice == 'Y' or choice == 'y':\n",
    "            print('User input = Yes\\n')\n",
    "            choice = True\n",
    "            answered = True\n",
    "        elif choice == 'N' or choice == 'n':\n",
    "            choice = False\n",
    "            answered = True\n",
    "            print('User input = No\\n')\n",
    "        else:\n",
    "            choice=choice\n",
    "            print('Error, please use the character inputs \\'Y\\' and \\'N\\'')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e785c5c",
   "metadata": {},
   "source": [
    "## Import Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67c90468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cnn_model_functions import *\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    '''\n",
    "    Inherits Class information from the nn.Module and creates a Classifier Class:\n",
    "        - Class has these attributes:\n",
    "            o fully connected layer with specified number of in_features and out_features\n",
    "            o number of hidden layers equivalent to the inputted requirements\n",
    "            o dropout parameter for the fully connected layers\n",
    "        - Class has a forward method:\n",
    "            o Flattens the input data in an input layer for computation\n",
    "            o Connects each layer with a relu activation, the defined dropout, and linear regression\n",
    "            o Returns outputs from the final hidden layer into an categorical output probability using log_softmax\n",
    "    Parameters:\n",
    "        - in_features\n",
    "        - hidden_layers\n",
    "        - out_features\n",
    "    '''\n",
    "    # Initialize attributes, requiring input arguments for the number of hidden layers, and input and output features\n",
    "    # Use super() for multiple inheritance from nn.Module, use arguments to create in, out, hidden layer attributes\n",
    "    def __init__(self, in_features, hidden_layers, out_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.out_features = out_features\n",
    "        self._index = 1\n",
    "\n",
    "        # Iterate to create the requested number of hidden layers, tapering down shape by a factor of 2 between layers\n",
    "        # Setattr is used to create a layer attribute with the fc('index') name and the factored shape\n",
    "        # Use the required number of out features for the output of the last layer, set dropout to a desired value\n",
    "        while self._index < self.hidden_layers:\n",
    "            setattr(self, 'fc'+str(self._index), nn.Linear(round(self.in_features/(2**(self._index-1))),\n",
    "                            round(self.in_features/(2**self._index))))\n",
    "            self._index += 1\n",
    "        setattr(self, 'fc'+str(self._index), nn.Linear(round(self.in_features/(2**(self._index-1))), self.out_features))\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "    # Define the forward function that will take an input and compute it through the number of layers\n",
    "    # Start by flattening the data, then use the number of hidden layers to iterate through each existing layer\n",
    "    # Use the Relu activation function between layers, apply the defined dropout rate, and return the softmax probability\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        self._index = 1\n",
    "        while self._index < self.hidden_layers:\n",
    "            x = self.dropout(F.relu(getattr(self,'fc'+str(self._index))(x)))\n",
    "            self._index += 1\n",
    "        x = F.log_softmax(getattr(self,'fc'+str(self._index))(x), dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "def m1_create_classifier(model_name, hidden_layers, classes_length):\n",
    "    '''\n",
    "    Purpose:\n",
    "        - Return an integrated CNN architecture by:\n",
    "            o downloading a pretrained model\n",
    "            o attaching a fully connected network\n",
    "        - Leverages the requested pretrained model to provide base features\n",
    "    Parameters:\n",
    "        - model_name = base pretrained model\n",
    "        - hidden_layers = number of hidden layers in final fully connected network\n",
    "        - out_features = number of classes in data\n",
    "    Returns:\n",
    "        - model\n",
    "    '''\n",
    "    # Store a dictionary of available models as names to avoid downloading models until a choice has been made\n",
    "    model_name_dic = {'vgg': 'vgg16', 'alexnet': 'alexnet', 'googlenet': 'googlenet', 'densenet': 'densenet161',\n",
    "                      'resnext': 'resnext50_32x4d', 'shufflenet': 'shufflenet_v2_x1_0'}\n",
    "\n",
    "    # Download the pretrained convolutional neural network architecture requested by the user and freeze the parameters\n",
    "    model = getattr(models, model_name_dic[model_name])(pretrained=True)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Search the pretrained architecture for the first fully-connected layer and return the number of in features\n",
    "    for module in list(model.modules()):\n",
    "        if module._get_name() == 'Linear':\n",
    "            in_features = module.weight.shape[1]\n",
    "            break\n",
    "\n",
    "    # Use the known number of in and out features to ensure compatibility for the attached fully connected layers\n",
    "    # Replace the fully connected layer(s) at the end of the model with our own fully connected classifier\n",
    "    setattr(model, list(model._modules.items())[-1][0], Classifier(in_features, hidden_layers, classes_length))\n",
    "\n",
    "    # Print the name of the model and the architecture of the attached layers, then return the model\n",
    "    print('\\nUsing ', model_name, ' with the following attached ', hidden_layers,\n",
    "                    ' layer classifier:\\n', list(model.children())[-1])\n",
    "    return model\n",
    "\n",
    "\n",
    "def m2_save_model_checkpoint(model, file_name_scheme, model_hyperparameters):\n",
    "    '''\n",
    "    Purpose:\n",
    "        - Receive a model, a naming convention, and model hyperparameter\n",
    "        - Save model checkpoint and hyperparameters\n",
    "    Parameters:\n",
    "        - model = model to be saved\n",
    "        - file_name_scheme = directory and naming convention for saving\n",
    "        - model_hyperparameters = information about state of model\n",
    "    Returns:\n",
    "        - none\n",
    "    '''\n",
    "    # Save the model state_dict per the naming convention as a pth file\n",
    "    torch.save(model.state_dict(), file_name_scheme + '_dict.pth')\n",
    "\n",
    "    # Save the model hyperparameters per the naming convention as a JSON file\n",
    "    with open(file_name_scheme + '_hyperparameters.json', 'w') as file:\n",
    "        json.dump(model_hyperparameters, file)\n",
    "\n",
    "\n",
    "def m3_load_model_checkpoint(model, file_name_scheme):\n",
    "    '''\n",
    "    Purpose:\n",
    "        - Receive a model, a naming convention, and model hyperparameters\n",
    "        - Load model checkpoint and hyperparameters\n",
    "    Parameters:\n",
    "        - model = model to be loaded\n",
    "        - file_name_scheme = directory and naming convention for loading\n",
    "    Returns:\n",
    "        - model\n",
    "        - model hyperparameters\n",
    "    '''\n",
    "    # Load the model state_dict by using the naming convention to find the file\n",
    "    checkpoint = torch.load(file_name_scheme + '_dict.pth')\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    # Load the model hyperparameters by using the naming convention and display the learnrate and train time\n",
    "    with open(file_name_scheme + '_hyperparameters.json', 'r') as file:\n",
    "        model_hyperparameters = json.load(file)\n",
    "    print('\\nThe loaded model learnrate = {:.2e}..'.format( model_hyperparameters['learnrate']),\n",
    "          'The loaded model training time = {:.0f} min\\n'.format( model_hyperparameters['training_time']))\n",
    "    return model, model_hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93273f2",
   "metadata": {},
   "source": [
    "## Import Operational Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f122f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cnn_operational_functions  import *\n",
    "\n",
    "def o1_train_model(model, train_loader, valid_loader, epoch, decay, model_hyperparameters, criterion):\n",
    "    '''\n",
    "    Purpose:\n",
    "        - Receive a model and start or continue training on it for e epochs\n",
    "    Parameters:\n",
    "        - model = inputted model (can be loaded with training history)\n",
    "        - train_loader = data loader for training data for iterating\n",
    "        - valid_loader = data loader for validation data for iterating\n",
    "        - epoch = number of epochs to train\n",
    "        - model_hyperparameters = dictionary of model hyperparameter information\n",
    "        - criterion = the loss calculation method\n",
    "    Returns:\n",
    "        - model = model after e epochs of training\n",
    "        - model_hyperparameters = revised hyperparameters for model after training\n",
    "    '''\n",
    "    # Print the GPU information or indicate that the GPU is not available if there is an issue\n",
    "    print('Using GPU =', torch.cuda.get_device_name(), round(torch.cuda.get_device_properties(0).total_memory*(10**-9)), 'GB'\\\n",
    "                    if torch.cuda.is_available() else \"WARNING GPU UNAVAILABLE\")\n",
    "\n",
    "    # Initialize a reference start time and subtract previous training time from reference point\n",
    "    # Document starting learnrate and initialize a Boolean running variable to track deeper layer training\n",
    "    t0 = time.time() - model_hyperparameters['training_time']*60\n",
    "    startlearn = model_hyperparameters['learnrate']\n",
    "    running = False\n",
    "\n",
    "    # Set the optimizer for backpropogation. All parameters are set so that when unfrozen, they are included in backprop\n",
    "    # NOTE: optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay= wd) to access unfrozen params\n",
    "    optimizer = optim.Adam(model.parameters(), lr=model_hyperparameters['learnrate'], weight_decay=model_hyperparameters['weightdecay'])\n",
    "\n",
    "    # Run the requested number of epochs worth of training by iterating e through the range of epochs\n",
    "    for e in range(epoch):\n",
    "        # Call backprop function with training data and model to return an updated model and the epoch training loss\n",
    "        # Call validation function (no backprop) with the validation data and model and return performance data\n",
    "        model, ave_training_loss = o2_model_backprop(model, train_loader, optimizer, criterion)\n",
    "        val_count_correct, ave_validate_loss = o3_model_no_backprop(model, valid_loader, criterion)\n",
    "\n",
    "        # Update the training history log with the average training loss and validation loss for this epoch\n",
    "        model_hyperparameters['training_loss_history'].append(ave_training_loss)\n",
    "        model_hyperparameters['validate_loss_history'].append(ave_validate_loss)\n",
    "\n",
    "        # Print the epoch loss, accuracy, GPU usage, and runtime data. Accuracy is total correct over total in data\n",
    "        print('Epoch: {}/{}..'.format(e+1, epoch),\n",
    "            'Train Loss: {:.3f}..'.format(ave_training_loss),\n",
    "            'Valid Loss: {:.3f}..'.format(ave_validate_loss),\n",
    "            'Valid Accy: {:.2f}..'.format(val_count_correct / len(valid_loader.dataset)),\n",
    "            'Mem: {:.2f}GB..'.format(np.around(torch.cuda.memory_allocated()*(10**-9), decimals=2)),\n",
    "            'Time: {:.0f}min'.format((time.time() - t0)/60))\n",
    "\n",
    "        # Reassigned model_hyperparameters['training_loss_history'] for this section to tlh for readability\n",
    "        tlh = model_hyperparameters['training_loss_history']\n",
    "        # This next section determines when to adjust learning based on training progress\n",
    "        # This section is mainly a for fun exercise to tune a math algorithm for deciding when to adjust training\n",
    "        # Hold loop until training_loss_history has enough elements to satisfy search requirements\n",
    "        if len(tlh) > 3: # NOTE: 2\n",
    "            # Compute reference: 3 times the first training loss factored by the current learnrate and the decay squared\n",
    "            # Compute progress in training: the average of the last 2 training loss slopes\n",
    "            # If progress in training is inverted sufficient enough to be greater than the reference, decay learnrate\n",
    "            if 3*model_hyperparameters['learnrate']*decay*decay*tlh[0] < np.mean([tlh[-1]-tlh[-2], tlh[-2]-tlh[-3]]):\n",
    "                model_hyperparameters['learnrate'] *= decay # multiply learnrate by the decay hyperparameter\n",
    "                optimizer = optim.Adam(model.parameters(), lr=model_hyperparameters['learnrate'], weight_decay=model_hyperparameters['weightdecay']) # revise the optimizer to use the new learnrate\n",
    "                print('Learnrate changed to: {:f}'.format(model_hyperparameters['learnrate']))\n",
    "            # Compute reference: starting learnrate factored by decay^(9*decay^3))\n",
    "            # Once learnrate has decayed to less than this value, call control_model_grad to activate deep layer training\n",
    "            # Don't call if deep layer training has already been activated, set running to True to begin counting\n",
    "            # In practice this performed well for various models and for overfitting vs regular training\n",
    "            if model_hyperparameters['learnrate'] <= startlearn*decay**(9*(decay**3)) and model_hyperparameters['running_count'] == 0:\n",
    "                model = o4_control_model_grad(model, True)\n",
    "                model_hyperparameters['epoch_on'] = e\n",
    "                running = True\n",
    "            # If running, add to model running count to track the number of epochs run\n",
    "            if running:\n",
    "                model_hyperparameters['running_count'] +=1\n",
    "            # Once the deep layers have trained for 20 epochs, call control_model_grad to deactivate deep layer training\n",
    "            # Set the running variable to False to stop counting and prevent recalling deactivate layers\n",
    "            if running and model_hyperparameters['running_count'] > 20:\n",
    "                model = o4_control_model_grad(model, False)\n",
    "                running = False\n",
    "            # Find the basename of the loader's file root and check if it is overfit data\n",
    "            # If overfit data, see if the train loss has gone below a target. If so end and print success\n",
    "            # If the train loss has not gone below the target and the epochs have elapsed, print failure\n",
    "            if os.path.basename(train_loader.dataset.root) == 'overfit':\n",
    "                if np.mean([tlh[-1], tlh[-2], tlh[-3]]) < 0.0001:\n",
    "                    print('\\nModel successfully overfit images\\n')\n",
    "                    return model, model_hyperparameters\n",
    "                if e+1 == epoch:\n",
    "                    print('\\nModel failed to overfit images\\n')\n",
    "\n",
    "    # Document the training time for the model and return the trained model and hyperparameters\n",
    "    model_hyperparameters['training_time'] = np.around((time.time() - t0)/60, decimals=1)\n",
    "    return model, model_hyperparameters\n",
    "\n",
    "\n",
    "def o2_model_backprop(model, data_loader, optimizer, criterion):\n",
    "    '''\n",
    "    Purpose:\n",
    "        - Conduct backpropogation on a model for data from a dataloader\n",
    "    Parameters:\n",
    "        - model = inputted model\n",
    "        - data_loader = generator for data to provide model training\n",
    "        - optimizer = defined optimizer for backpropogation\n",
    "        - criterion = the loss calculation method\n",
    "    Returns:\n",
    "        - model = model after cycling through the data_loader (one epoch of training)\n",
    "        - ave_training_loss = averaged training loss per batch of data\n",
    "    '''\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Set device to GPU if available\n",
    "    torch.cuda.empty_cache() # refresh GPU memory before starting\n",
    "    model.to(device) # Move model to device\n",
    "    epoch_train_loss = 0 # initialize total training loss for this epoch\n",
    "    model.train() # Set model to training mode to activate regularizations such as dropout\n",
    "\n",
    "    for images, labels in data_loader: # cycle through training data to conduct backpropogation\n",
    "        images, labels = images.to(device), labels.to(device) # move data to GPU\n",
    "\n",
    "        optimizer.zero_grad() # clear gradient history\n",
    "        log_out = model(images) # run images through model to get logarithmic probability\n",
    "        loss = criterion(log_out, labels) # calculate loss (error) for this image batch based on criterion\n",
    "\n",
    "        loss.backward() # backpropogate gradients through model based on error\n",
    "        optimizer.step() # update weights in model based on calculated gradient information\n",
    "        epoch_train_loss += loss.item() # add training loss to total train loss this epoch, convert to value with .item()\n",
    "\n",
    "    ave_training_loss = epoch_train_loss / len(data_loader.dataset) # determine average loss per training image\n",
    "    return model, ave_training_loss # return the updated model and the average training loss\n",
    "\n",
    "\n",
    "def o3_model_no_backprop(model, data_loader, criterion):\n",
    "    '''\n",
    "    Purpose:\n",
    "        - Use the model to conduct predictions using the model\n",
    "        - Return performance of the predictions across the data\n",
    "    Parameters:\n",
    "        - model = inputted model\n",
    "        - data_loader = generator for data to conduct predictions\n",
    "        - criterion = the loss calculation method\n",
    "    Returns:\n",
    "        - val_count_correct = number of correctly predicted data items\n",
    "        - ave_validate_loss = averaged criterion loss per batch of data\n",
    "    '''\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Set device to GPU if available\n",
    "    torch.cuda.empty_cache() # refresh GPU memory before starting\n",
    "    model.to(device) # Move model to device\n",
    "    epoch_valid_loss = 0 # initialize total validate loss for this epoch\n",
    "    val_count_correct = 0 # initialize total correct predictions on valid set\n",
    "    model.eval() # set model to evaluate mode to deactivate generalizing operations such as dropout and leverage full model\n",
    "\n",
    "    with torch.no_grad(): # turn off gradient tracking and calculation for computational efficiency\n",
    "        for images, labels in data_loader: # cycle through validate data to observe performance\n",
    "            images, labels = images.to(device), labels.to(device) # move data to GPU\n",
    "\n",
    "            log_out = model(images) # run images through model to get logarithmic probability\n",
    "            loss = criterion(log_out, labels) # calculate loss (error) for this image batch based on criterion\n",
    "            epoch_valid_loss += loss.item() # add validate loss to total valid loss this epoch, convert to value with .item()\n",
    "\n",
    "            out = torch.exp(log_out) # obtain probability from the logarithmic probability calculated by the model\n",
    "            highest_prob, chosen_class = out.topk(1, dim=1) # obtain the top classes and probabilities from the output\n",
    "            equals = chosen_class.view(labels.shape) == labels # determine how many correct matches were made in this batch\n",
    "            val_count_correct += equals.sum()  # add the count of correct matches this batch to the total number this epoch\n",
    "\n",
    "        ave_validate_loss = epoch_valid_loss / len(data_loader.dataset) # determine average loss per validate image\n",
    "    return val_count_correct, ave_validate_loss # return this epoch's total correct predictions and average training loss\n",
    "\n",
    "\n",
    "def o4_control_model_grad(model, control=False):\n",
    "    '''\n",
    "    Purpose:\n",
    "        - Input a model and control active gradients on parameters at various layer depths\n",
    "        - Print which layes have been controlled\n",
    "    Parameters:\n",
    "        - model = inputted model\n",
    "        - control = whether to activate or deativate gradients\n",
    "    Returns:\n",
    "        - model = edited model with controlled layers\n",
    "    '''\n",
    "    # NOTE: Don't use model.children for network_depth, as this does not capture sublayers!\n",
    "    network_depth = len(list(model.modules())) # Obtain the length of the layers used in the network\n",
    "    param_freeze_depth = network_depth // 3 # Define what fraction of the network will be frozen and unfrozen\n",
    "    controlled_layers = [] # Initialize the controlled layers list that will track what is frozen and unfrozen\n",
    "    layer_depth = 0 # Initialize the start for iterating through layers\n",
    "\n",
    "    for layer in list(model.modules()): # Iterate through layers in the model\n",
    "        layer_depth += 1 # Increase current layer depth by 1 to progress through network layers\n",
    "\n",
    "        if (network_depth - param_freeze_depth) <= layer_depth: # Once sufficiently deep, control layers\n",
    "            controlled_layers.append(layer._get_name()) # Add current layer's name to list of controlled layers\n",
    "            for param in layer.parameters(): # Iterate through the parameters in this layer\n",
    "                param.requires_grad = control # Freeze or unfreeze the gradient on the parameter\n",
    "\n",
    "        if layer._get_name() == 'Linear': # The fully connected layers are always unfrozen\n",
    "            for param in layer.parameters(): # Iterate parameters\n",
    "                param.requires_grad = True # Set gradient to true\n",
    "\n",
    "    print(f'\\n Toggle requires_grad = {control}: ', controlled_layers, '\\n') # Print changes made to active grads\n",
    "    return model # Return model with changed param activity\n",
    "\n",
    "\n",
    "def o5_plot_training_history(model_name, model_hyperparameters, file_name_scheme, train_type='loaded'):\n",
    "    '''\n",
    "    Purpose:\n",
    "        - Plot the training and validation loss history for the inputted model\n",
    "        - Plot lines indicating when layers were activated and deactivated if controlled\n",
    "        - Save the plot with the name according to the type of training, skip if a loaded version\n",
    "    Parameters:\n",
    "        - model_name = name of model, used for title on plot\n",
    "        - model_hyperparameters = contains the history for plotting\n",
    "        - file_name_scheme = directory and naming convention for loading\n",
    "        - train_type = offer control on saving\n",
    "    Returns:\n",
    "        - none\n",
    "    '''\n",
    "    # Plot training history information\n",
    "    plt.clf()\n",
    "    plt.plot(model_hyperparameters['training_loss_history'], label='Training Training Loss')\n",
    "    plt.plot(model_hyperparameters['validate_loss_history'], label='Validate Training Loss')\n",
    "\n",
    "    # If deep layer training has started, plot dotted lines for start and finish\n",
    "    if model_hyperparameters['epoch_on']:\n",
    "        plt.vlines(\n",
    "            colors = 'black',\n",
    "            x = model_hyperparameters['epoch_on'],\n",
    "            ymin = min(model_hyperparameters['training_loss_history']),\n",
    "            ymax = max(model_hyperparameters['training_loss_history'][3:]),\n",
    "            linestyles = 'dotted',\n",
    "            label = 'Deep Layers Activated'\n",
    "        ).set_clip_on(False)\n",
    "        plt.vlines(\n",
    "            colors = 'black',\n",
    "            x = (model_hyperparameters['epoch_on'] + model_hyperparameters['running_count']),\n",
    "            ymin = min(model_hyperparameters['training_loss_history']),\n",
    "            ymax = max(model_hyperparameters['training_loss_history'][3:]),\n",
    "            linestyles = 'dotted',\n",
    "            label = 'Deep Layers Deactivated'\n",
    "        ).set_clip_on(False)\n",
    "\n",
    "    # Plot title and labels\n",
    "    plt.title(model_name)\n",
    "    plt.ylabel('Total Loss')\n",
    "    plt.xlabel('Total Epoch ({})'.format(len(model_hyperparameters['training_loss_history'])))\n",
    "    plt.legend(frameon=False)\n",
    "\n",
    "    # If the plot was not loaded, save the plot using the naming convention\n",
    "    if train_type != 'loaded':\n",
    "        plt.savefig(file_name_scheme + '_training_history_' + train_type + '.png')\n",
    "        print('Saved', train_type, 'training history to project directory')\n",
    "\n",
    "    # Show plot and unblock to allow function continuation, pause to load image and avoid from freezing\n",
    "    plt.show(block=False)\n",
    "    plt.pause(2)\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "def o6_predict_data(model, data_loader, dict_data_labels, dict_class_labels, topk=5):\n",
    "    '''\n",
    "    Purpose:\n",
    "        - Compute probabilities for various classes for an image using a model\n",
    "    Parameters:\n",
    "        - model = trained deep neural net for computation\n",
    "        - data_loader = generator for data items to be iterated through for parallel prediction\n",
    "        - dict_data_labels = dictionary containing the names of each class for the data indexes\n",
    "        - dict_class_labels = dictionary containing the class indexes for the data indexes\n",
    "        - topk = number of class outputs\n",
    "    Returns:\n",
    "        - dict_prediction_results = dictionary containing predictions and probabilities for data keys\n",
    "    '''\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # set device to GPU if available\n",
    "    torch.cuda.empty_cache() # refresh GPU memory before starting\n",
    "    model.to(device) # move model to device\n",
    "    dict_prediction_results = {} # initialize the prediction results dictionary\n",
    "    model.eval() # set model to evaluate mode to deactivate generalizing operations such as dropout and leverage full model\n",
    "    if len(dict_class_labels) < topk: # confirm there are enough different classes to satisfy results ranking\n",
    "        topk = len(dict_class_labels) # replace number of ranked results to the number of classes if not\n",
    "\n",
    "    with torch.no_grad(): # turn off gradient tracking and calculation for computational efficiency\n",
    "        for image, filenames in data_loader: # cycle through data for inference\n",
    "            image = image.to(device) # move data to GPU\n",
    "\n",
    "            log_out = model(image) # run images through model to get logarithmic probability\n",
    "            model_output = torch.exp(log_out) # obtain probability from the logarithmic probability\n",
    "            probabilities, class_indexes = model_output.topk(topk, dim=1) # obtain the top results\n",
    "\n",
    "            for index in np.arange(len(filenames)):# iterate through filenames batch with index\n",
    "                # Find the class prediction name by comparing the class label dictionary to the data label dictionary\n",
    "                if dict_data_labels:\n",
    "                    class_prediction = [dict_data_labels[dict_class_labels[value]] for value in class_indexes.tolist()[index]]\n",
    "                else:\n",
    "                    class_prediction = [dict_class_labels[value] for value in class_indexes.tolist()[index]]\n",
    "                # Then add this filename to the prediction results dictionary with the corresponding results and\n",
    "                dict_prediction_results[filenames[index]] = [class_prediction, probabilities.tolist()[index]]\n",
    "    return dict_prediction_results # Return\n",
    "\n",
    "\n",
    "def o7_show_prediction(data_dir, dict_prediction_results):\n",
    "    '''\n",
    "    Purpose:\n",
    "        - Randomly choose a piece of data from the predict folder\n",
    "        - Display the chosen data and display the class outputs and corresponding probabilities\n",
    "    Parameters:\n",
    "        - data_dir = pathway to the data directory containing the data of interest\n",
    "        - dict_prediction_results = dictionary of the prediction results on the dataset of interest\n",
    "    Returns:\n",
    "        - none\n",
    "    '''\n",
    "    # Randomly select an example file to conduct a prediction\n",
    "    example_prediction = random.choice(list(dict_prediction_results.keys()))\n",
    "\n",
    "    # Open and show the prediction\n",
    "    plt.imshow(Image.open(data_dir + 'predict/' + example_prediction)); # no need to process and inverse transform, our data is coming from the same path, I'll just open the original\n",
    "    plt.show(block=False)\n",
    "    plt.pause(2)\n",
    "    plt.close()\n",
    "\n",
    "    # Plot the predicted class, the probabilities, and use the data's filename for the title\n",
    "    plt.bar(dict_prediction_results[example_prediction][0], dict_prediction_results[example_prediction][1])\n",
    "    plt.title(example_prediction)\n",
    "    plt.xticks(rotation=20);\n",
    "    plt.show(block=False)\n",
    "    plt.pause(3)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8224b6c5",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f6e6977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukea/Programming Data/Flower_data/models/Flower_data_googlenet_2lay\n",
      "\n",
      "Using  googlenet  with the following attached  2  layer classifier:\n",
      " Classifier(\n",
      "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=102, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n",
      "Check model can overfit small dataset?: 'y' for yes, 'n' for no (10 seconds to choose): y\n",
      "User input = Yes\n",
      "\n",
      "Using GPU = NVIDIA GeForce GTX 1050 4 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukea\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50.. Train Loss: 0.576.. Valid Loss: 0.041.. Valid Accy: 0.01.. Mem: 0.03GB.. Time: 0min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31980/3214212180.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31980/3214212180.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0margtrain\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'n'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0margload\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'n'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mu5_time_limited_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Check model can overfit small dataset?'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             overfit_model, overfit_model_hyperparameters = o1_train_model(model, dict_data_loaders['overfit_loader'],\n\u001b[0m\u001b[0;32m     74\u001b[0m                             dict_data_loaders['valid_loader'], argepoch, 0.9, model_hyperparameters, criterion)\n\u001b[0;32m     75\u001b[0m             \u001b[0mo5_plot_training_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverfit_model_hyperparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name_scheme\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'overfit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31980/2748727399.py\u001b[0m in \u001b[0;36mo1_train_model\u001b[1;34m(model, train_loader, valid_loader, epoch, decay, model_hyperparameters, criterion)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# Call validation function (no backprop) with the validation data and model and return performance data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mave_training_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo2_model_backprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mval_count_correct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mave_validate_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo3_model_no_backprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m# Update the training history log with the average training loss and validation loss for this epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31980/2748727399.py\u001b[0m in \u001b[0;36mo3_model_no_backprop\u001b[1;34m(model, data_loader, criterion)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# move data to GPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0mlog_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# run images through model to get logarithmic probability\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# calculate loss (error) for this image batch based on criterion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[0mepoch_valid_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# add validate loss to total valid loss this epoch, convert to value with .item()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\models\\googlenet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mGoogLeNetOutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[0maux_defined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maux_logits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\models\\googlenet.py\u001b[0m in \u001b[0;36m_forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;31m# N x 3 x 224 x 224\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m         \u001b[1;31m# N x 64 x 112 x 112\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxpool1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\models\\googlenet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \"\"\"\n\u001b[1;32m--> 167\u001b[1;33m         return F.batch_norm(\n\u001b[0m\u001b[0;32m    168\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2279\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2281\u001b[1;33m     return torch.batch_norm(\n\u001b[0m\u001b[0;32m   2282\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2283\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    '''\n",
    "    # Retrieve command line arguments to dictate model type, training parameters, and data\n",
    "    # Load image datasets, process the image data, and convert these into data generators\n",
    "    # Create a default naming structure to save and load information at a specified directory\n",
    "    # Download a pretrained model using input arguments and attach new fully connected output Layers\n",
    "    # Define criterion for loss, if training is required by the input arg, execute the following:\n",
    "    #    o Prompt user for overfit training, if yes, initiate training against pretrained features\n",
    "    #    o Prompt user for complete training, if yes, initiate training against pretrained features\n",
    "    #    o Save the hyperparameters, training history, and training state for the overfit and full models\n",
    "    # If training is no requested by the input arg, execute the following:\n",
    "    #    o Load in a pretrained model's state dict and it's model_hyperparameters\n",
    "    #    o Display the training history for this model\n",
    "    # Provide prompt to test the model and perform and display performance if requested\n",
    "    # Provide prompt to apply the model towards inference and put model to work if requested\n",
    "    # Show an example prediction from the inference\n",
    "    '''\n",
    "    # Call ArgumentParser for user arguments and store in arg\n",
    "    data_dir = os.path.expanduser('~') + '/Programming Data/' + argdir + '/'\n",
    "\n",
    "    # Call data processor to return a dictionary of datasets, the data labels, and the class labels\n",
    "    dict_datasets, dict_data_labels, dict_class_labels = u2_load_processed_data(data_dir)\n",
    "\n",
    "    # Call data iterator to convert dictionary of datasets to dictionary of dataloaders\n",
    "    dict_data_loaders = u4_data_iterator(dict_datasets)\n",
    "\n",
    "    #Create file pathway and naming convention saving and loading files in program\n",
    "    file_name_scheme =  data_dir + 'models/' + os.path.basename(os.path.dirname(data_dir))\\\n",
    "                    + '_' + argmodel + '_' + str(arglayer) + 'lay'\n",
    "    print(file_name_scheme)\n",
    "    # Call create classifier to return a model leveraging a desired pretrained architecture, define loss criterion\n",
    "    model = m1_create_classifier(argmodel, arglayer, len(dict_datasets['train_data'].classes))\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    # Define start condition hyperparameters and key running information such as elapsed training time\n",
    "    # epoch_on and running_count refer to the epoch in which deeper layers started training and for how long\n",
    "    model_hyperparameters = {'learnrate': arglearn,\n",
    "                         'training_loss_history': [],\n",
    "                         'validate_loss_history': [],\n",
    "                         'epoch_on': [],\n",
    "                         'running_count': 0,\n",
    "                         'weightdecay' : 0.00001,\n",
    "                         'training_time' : 0}\n",
    "\n",
    "    # If user requests load, call load checkpoint to return model and hyperparameters, then plot loaded information\n",
    "    if argload == 'y':\n",
    "        model, model_hyperparameters = m3_load_model_checkpoint(model, file_name_scheme)\n",
    "        o5_plot_training_history(argmodel, model_hyperparameters, file_name_scheme)\n",
    "\n",
    "    # If user requests train, first display an example piece of data from the processed training set\n",
    "    if argtrain == 'y':\n",
    "        # NOTE 1: Processed data is tensor shape [xpixel, ypixel, colour], matplotlib takes order [c, x, y], so we transpose\n",
    "        # NOTE 2: Plotted images blocks function continuation, unblock requires pause to load image or image will freeze\n",
    "        print('Displaying an example processed image from the training set..\\n')\n",
    "        plt.imshow(random.choice(dict_datasets['train_data'])[0].numpy().transpose((1, 2, 0))) # NOTE: 1\n",
    "        plt.show(block=False) # NOTE: 2\n",
    "        plt.pause(2)\n",
    "        plt.close()\n",
    "\n",
    "        # Call train model with model and training dataset to return trained model and hyperparameters, then plot and save\n",
    "        model, model_hyperparameters = o1_train_model(model, dict_data_loaders['train_loader'],\n",
    "                        dict_data_loaders['valid_loader'], argepoch, 0.6, model_hyperparameters, criterion)\n",
    "        o5_plot_training_history(argmodel, model_hyperparameters, file_name_scheme, 'complete')\n",
    "\n",
    "        # Prompt user to save, save the model and its hyperparameters per the naming convention\n",
    "        if u5_time_limited_input('Would you like to save the model?'):\n",
    "            m2_save_model_checkpoint(model, file_name_scheme, model_hyperparameters)\n",
    "\n",
    "    # If user requests no load and no train, prompt to run an overfit training exercise and execute if requested\n",
    "    # NOTE: Same as training but on an overfit dataset. overfit_model metadata references the same data as the model metadata\n",
    "    if argtrain == 'n' and argload == 'n':\n",
    "        if u5_time_limited_input('Check model can overfit small dataset?'):\n",
    "            overfit_model, overfit_model_hyperparameters = o1_train_model(model, dict_data_loaders['overfit_loader'],\n",
    "                            dict_data_loaders['valid_loader'], argepoch, 0.9, model_hyperparameters, criterion)\n",
    "            o5_plot_training_history(argmodel, overfit_model_hyperparameters, file_name_scheme, 'overfit')\n",
    "\n",
    "    # If user requests load, or has requested training and training has completed, the model is ready for predictions\n",
    "    if argtrain == 'y' or argload == 'y':\n",
    "        print('The model is ready to provide predictions\\n')\n",
    "\n",
    "        # Prompt to test the model's performance\n",
    "        # Gives the testing data loader to the validation function and returns performance\n",
    "        if u5_time_limited_input('Would you like to test the model?'):\n",
    "            t0 = time.time()\n",
    "            test_count_correct, ave_test_loss = o3_model_no_backprop(model, dict_data_loaders['test_loader'], criterion)\n",
    "            print('\\nTesting Loss: {:.3f}.. '.format(ave_test_loss),\n",
    "                'Testing Accuracy: {:.3f}'.format(test_count_correct / len(dict_data_loaders['test_loader'].dataset)),\n",
    "                'Runtime - {:.0f} seconds\\n'.format((time.time() - t0)))\n",
    "\n",
    "        # Prompt the user to use the model for inference\n",
    "        # Gives an unlabeled dataloader to a predict function and returns predictions\n",
    "        if u5_time_limited_input('Would you like to use the model for inference?'):\n",
    "            t1 = time.time()\n",
    "            dict_prediction_results = o6_predict_data(model, dict_data_loaders['predict_loader'],\n",
    "                            dict_data_labels, dict_class_labels)\n",
    "            o7_show_prediction(data_dir, dict_prediction_results)\n",
    "            print('Runtime - {:.0f} seconds\\n'.format((time.time() - t1)),\n",
    "                            [dict_prediction_results[key][0][0] for key in dict_prediction_results])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf4272d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
