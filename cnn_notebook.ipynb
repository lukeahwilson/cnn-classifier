{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "164be129",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os, random\n",
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch import nn, optim\n",
    "from PIL import Image\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6ec94d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "argtrain = 'y'\n",
    "argepoch = 100\n",
    "argmodel = 'googlenet'\n",
    "arglabel = 'flower_to_name.json'\n",
    "argdir = os.path.expanduser('~') + '/Programming Data/Flower_data/'\n",
    "arglearn = 0.003\n",
    "arglayer = 3\n",
    "\n",
    "# 'vgg', 'alexnet', 'googlenet', 'densenet', 'inception', 'resnext', 'shufflenet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4b7ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cnn_utility_functions import *\n",
    "\n",
    "def u1_get_input_args():\n",
    "    \"\"\"\n",
    "    Creates and stores command line arguments inputted by the user. Attaches default arguments and help text to aid user.\n",
    "    Command Line Arguments:\n",
    "        1. Directory as --dir\n",
    "        2. CNN Model as --model\n",
    "        3. Data Name Dictionary as --names\n",
    "    This function returns these arguments as an ArgumentParser object.\n",
    "    Parameters:\n",
    "        - None\n",
    "    Returns:\n",
    "        - Stored command line arguments as an Argument Parser Object with parse_args() data structure\n",
    "    \"\"\"\n",
    "\n",
    "    parser = argparse.ArgumentParser(description = 'Classify input images and benchmark performance')\n",
    "    parser.add_argument('--dir', type=str, default= os.path.expanduser('~')+'/Programming Data/Flower_data/', help='input path for data directory')\n",
    "    parser.add_argument('--train', type=str, default='n', help='yes \\'y\\' or no \\'n\\' to retrain this model', choices=['y','n'])\n",
    "    parser.add_argument('--epoch', type=str, default=100, help='provide the number of epochs for training (default 100)')\n",
    "    parser.add_argument('--layer', type=str, default=2, help='provide the number of hidden layers to use (default 2)')\n",
    "    parser.add_argument('--learn', type=str, default=0.003, help='provide the learning rate to begin training (default 0.003)')\n",
    "    parser.add_argument('--label', type=str, default='', help='flower_to_name.json')\n",
    "    parser.add_argument('--model', type=str, default='googlenet', help='select pretrained model',\n",
    "                        choices=['vgg', 'alexnet', 'googlenet', 'densenet', 'resnext', 'shufflenet'])\n",
    "\n",
    "    return parser.parse_args() #return parsed arguments\n",
    "\n",
    "\n",
    "def u2_load_processed_data(data_dir):\n",
    "    \"\"\"\n",
    "    Receives a pathway to a folder containing training, .\n",
    "    Command Line Arguments:\n",
    "        1. Directory as --dir\n",
    "        2. CNN Model as --model\n",
    "        3. Data Name Dictionary as --names\n",
    "    This function returns these arguments as an ArgumentParser object.\n",
    "    Parameters:\n",
    "        - None\n",
    "    Returns:\n",
    "        - Stored command line arguments as an Argument Parser Object with parse_args() data structure\n",
    "    \"\"\"\n",
    "\n",
    "    dict_datasets = {}\n",
    "    for folder in os.listdir(data_dir):\n",
    "        if os.path.splitext(folder)[1] == '' and folder != 'predict':\n",
    "            dict_datasets[folder + '_data'] = datasets.ImageFolder(data_dir + folder, transform=u3_process_data(folder))\n",
    "        if os.path.splitext(folder)[1] == '' and folder == 'predict':\n",
    "            predict_transform = u3_process_data(folder)\n",
    "            dict_datasets['predict_data'] = [(predict_transform(Image.open(data_dir + folder + '/' + filename)), filename) for filename in os.listdir(data_dir + folder)]\n",
    "        if os.path.splitext(folder)[1] == '.json':\n",
    "            with open(data_dir + folder, 'r') as f:\n",
    "                dict_data_labels = json.load(f)\n",
    "    dict_class_labels = {value : key for (key, value) in dict_datasets['train_data'].class_to_idx.items()}\n",
    "    return dict_datasets, dict_data_labels, dict_class_labels\n",
    "\n",
    "\n",
    "def u3_process_data(transform_request):\n",
    "    #Define transforms for training, validation, overfitting, and test sets to convert to desirable tensors for processing\n",
    "\n",
    "    #Define image size\n",
    "    image_1d_size = 224\n",
    "\n",
    "    train_transform = transforms.Compose([transforms.RandomRotation(20),\n",
    "                                          transforms.RandomResizedCrop(image_1d_size),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "\n",
    "    valid_transform = transforms.Compose([transforms.Resize(int(np.round_(image_1d_size*1.1, decimals=0))),\n",
    "                                          transforms.CenterCrop(image_1d_size),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    test_transform = transforms.Compose([transforms.Resize(int(np.round_(image_1d_size*1.1, decimals=0))),\n",
    "                                         transforms.CenterCrop(image_1d_size),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    game_transform = transforms.Compose([transforms.Resize(int(np.round_(image_1d_size*1.1, decimals=0))),\n",
    "                                         transforms.CenterCrop(image_1d_size),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    \n",
    "    predict_transform = transforms.Compose([transforms.Resize(int(np.round_(image_1d_size*1.1, decimals=0))),\n",
    "                                            transforms.CenterCrop(image_1d_size),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    inverse_transform = transforms.Compose([transforms.Normalize([0, 0, 0], [1/0.229, 1/0.224, 1/0.225]),\n",
    "                                            transforms.Normalize([-0.485, -0.456, -0.406], [1, 1, 1])])\n",
    "\n",
    "    overfit_transform = train_transform\n",
    "\n",
    "    return locals()[transform_request + '_transform']\n",
    "\n",
    "\n",
    "def u4_data_iterator(dict_datasets):\n",
    "    '''\n",
    "    # bug, requires every folder to run correctly. Consider removing this function and nesting it directly into training function!\n",
    "    '''\n",
    "    dict_data_loaders = {}\n",
    "    dict_data_loaders['train_loader'] = torch.utils.data.DataLoader(dict_datasets['train_data'], batch_size=128, shuffle=True)\n",
    "    dict_data_loaders['valid_loader'] = torch.utils.data.DataLoader(dict_datasets['valid_data'], batch_size=64, shuffle=True)\n",
    "    dict_data_loaders['testing_loader'] = torch.utils.data.DataLoader(dict_datasets['test_data'], batch_size=32, shuffle=True)\n",
    "    dict_data_loaders['overfit_loader'] = torch.utils.data.DataLoader(dict_datasets['overfit_data'], batch_size=8, shuffle=True)\n",
    "    dict_data_loaders['predict_loader'] = torch.utils.data.DataLoader(dict_datasets['predict_data'], batch_size=2, shuffle=False)\n",
    "    \n",
    "    return dict_data_loaders\n",
    "\n",
    "\n",
    "def u5_time_limited_input(prompt):\n",
    "    TIMEOUT = 10\n",
    "    prompt = prompt + f': \\'y\\' for yes, \\'n\\' for no ({TIMEOUT} seconds to choose): '\n",
    "    user_input_thread = Thread(target=u6_user_input_prompt, args=(prompt,), daemon = True)\n",
    "    user_input_thread.start()\n",
    "    user_input_thread.join(TIMEOUT)\n",
    "    if not answered:\n",
    "        print('\\n No valid input, proceeding with operation...')\n",
    "    return choice\n",
    "\n",
    "\n",
    "def u6_user_input_prompt(prompt, default=True):\n",
    "    global choice, answered\n",
    "    choice = default\n",
    "    answered = False\n",
    "    while not answered:\n",
    "        choice = input(prompt)\n",
    "        if choice == 'Y' or choice == 'y':\n",
    "            print('User input = Yes\\n')\n",
    "            choice = True\n",
    "            answered = True\n",
    "        elif choice == 'N' or choice == 'n':\n",
    "            choice = False\n",
    "            answered = True\n",
    "            print('User input = No\\n')\n",
    "        else:\n",
    "            choice=choice\n",
    "            print('Error, please use the character inputs \\'Y\\' and \\'N\\'')\n",
    "\n",
    "\n",
    "# def u7_get_image(image_path):\n",
    "#     ''' Process raw image for input to deep learning model\n",
    "#     '''\n",
    "#     image_open = Image.open(image_path) # access image at pathway, open the image and store it as a PIL image\n",
    "#     tensor_image = flower_transform(image_open) # transform PIL image and simultaneously convert image to a tensor (no need for .clone().detach())\n",
    "#     input_image = torch.unsqueeze(tensor_image, 0) # change image shape from a stand alone image tensor, to a list of image tensors with length = 1\n",
    "#     return input_image # return processed image\n",
    "\n",
    "\n",
    "# def u8_show_image():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67c90468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From cnn_operational_functions.py import *\n",
    "\n",
    "def o1_train_model(model, dict_data_loaders, epoch, learnrate, type_loader, criterion):\n",
    "\n",
    "    print(\"Using GPU\" if torch.cuda.is_available() else \"WARNING\")\n",
    "    t0 = time.time() # initialize start time for running training\n",
    "\n",
    "    running_count = 0 # initialize running count in order to track number of epochs fine tuning deeper network\n",
    "    running = False # initialize running variable to start system with deeper network frozen\n",
    "\n",
    "    # Define default hyperparameters: learning rate and weight decay\n",
    "    model_hyperparameters = {'learnrate': learnrate,\n",
    "                         'training_loss_history': [],\n",
    "                         'validate_loss_history': [],\n",
    "                         'epoch_on': [],\n",
    "                         'running_count': 0,\n",
    "                         'weightdecay' : 0.00001}\n",
    "\n",
    "    startlearn = model_hyperparameters['learnrate']\n",
    "\n",
    "    # Only train the classifier (new_output) parameters, feature parameters are frozen\n",
    "    optimizer = optim.Adam(getattr(model, list(model._modules.items())[-1][0]).parameters(), lr=model_hyperparameters['learnrate'], weight_decay=model_hyperparameters['weightdecay'])\n",
    "\n",
    "    if type_loader == 'overfit_loader':\n",
    "        decay = 0.9 # hyperparameter decay factor for decaying learning rate\n",
    "        epoch = 200 # hyperparameter number of epochs\n",
    "\n",
    "    if type_loader == 'train_loader':\n",
    "        decay = 0.6 # hyperparameter decay factor for decaying learning rate\n",
    "\n",
    "    for e in range(epoch):\n",
    "\n",
    "        model, ave_training_loss = o2_model_backprop(model, dict_data_loaders[type_loader], optimizer, criterion)\n",
    "        epoch_count_correct, ave_validate_loss = o3_model_no_backprop(model, dict_data_loaders['valid_loader'], criterion)\n",
    "\n",
    "        model_hyperparameters['training_loss_history'].append(ave_training_loss) # append ave training loss to history of training losses\n",
    "        model_hyperparameters['validate_loss_history'].append(ave_validate_loss) # append ave validate loss to history of validate losses\n",
    "\n",
    "        print('Epoch: {}/{}.. '.format(e+1, epoch),\n",
    "            'Train Loss: {:.3f}.. '.format(ave_training_loss),\n",
    "            'Valid Loss: {:.3f}.. '.format(ave_validate_loss),\n",
    "            'Valid Accuracy: {:.3f}.. '.format(epoch_count_correct / len(dict_data_loaders['valid_loader'].dataset)),\n",
    "            'Runtime - {:.0f} mins'.format((time.time() - t0)/60))\n",
    "\n",
    "        training_loss_history = model_hyperparameters['training_loss_history']\n",
    "        if len(training_loss_history) > 3: # hold loop until training_loss_history has enough elements to satisfy search requirements\n",
    "            if -3*model_hyperparameters['learnrate']*decay*decay*training_loss_history[0] > np.mean([training_loss_history[-2]-training_loss_history[-1], training_loss_history[-3]-training_loss_history[-2]]):\n",
    "                # if the average of the last 2 training loss slopes is less than the original loss factored down by the learnrate, the decay, and a factor of 3, then decay the learnrate\n",
    "                model_hyperparameters['learnrate'] *= decay # multiply learnrate by the decay hyperparameter\n",
    "                optimizer = optim.Adam(getattr(model, list(model._modules.items())[-1][0]).parameters(), lr=model_hyperparameters['learnrate'], weight_decay=model_hyperparameters['weightdecay']) # revise the optimizer to use the new learnrate\n",
    "                print('Learnrate changed to: {:f}'.format(model_hyperparameters['learnrate']))\n",
    "            if model_hyperparameters['learnrate'] <= startlearn*decay**(9*(decay**3)) and model_hyperparameters['running_count'] == 0: # super messy, I wanted a general expression that chose when to activate the deeper network and this worked\n",
    "                model = o4_control_model_grad(model, True)\n",
    "                model_hyperparameters['epoch_on'] = e\n",
    "                running = True # change the running parameter to True so that the future loop can start counting epochs that have run\n",
    "            if running: # if running, add to count for the number of epochs run\n",
    "                model_hyperparameters['running_count'] +=1\n",
    "            if running and model_hyperparameters['running_count'] > epoch/5: # deactivate parameters if running, add the count has reached its limiter\n",
    "                model = o4_control_model_grad(model, False)\n",
    "                running = False\n",
    "            if type_loader == 'overfit_loader':\n",
    "                if np.mean([training_loss_history[-1], training_loss_history[-2], training_loss_history[-3]]) < 0.0002:\n",
    "                    print('\\nModel successfully overfit images\\n')\n",
    "                    return model, model_hyperparameters\n",
    "                if e+1 == epoch:\n",
    "                    print('\\nModel failed to overfit images\\n')\n",
    "\n",
    "    return model, model_hyperparameters\n",
    "\n",
    "\n",
    "def o2_model_backprop(model, data_loader, optimizer, criterion):\n",
    "    # Check model can overfit the data when using a miniscule sample size, looking for high accuracy on a few images\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.cuda.empty_cache()\n",
    "    model.to(device)\n",
    "\n",
    "    epoch_train_loss = 0 # initialize total training loss for this epoch\n",
    "    model.train() # Set model to training mode to activate operations such as dropout\n",
    "    for images, labels in data_loader: # cycle through training data\n",
    "        images, labels = images.to(device), labels.to(device) # move data to GPU\n",
    "\n",
    "        optimizer.zero_grad() # clear gradient history\n",
    "        log_out = model(images) # run image through model to get logarithmic probability\n",
    "        loss = criterion(log_out, labels) # calculate loss (error) for this image batch based on criterion\n",
    "\n",
    "        loss.backward() # backpropogate gradients through model based on error\n",
    "        optimizer.step() # update weights in model based on calculated gradient information\n",
    "        epoch_train_loss += loss.item() # add training loss to total train loss this epoch, convert to value with .item()\n",
    "    ave_training_loss = epoch_train_loss / len(data_loader) # determine average loss per batch of training images\n",
    "\n",
    "    return model, ave_training_loss\n",
    "\n",
    "\n",
    "def o3_model_no_backprop(model, data_loader, criterion):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    epoch_valid_loss = 0 # initialize total validate loss for this epoch\n",
    "    epoch_count_correct = 0 # initialize total correct predictions on valid set\n",
    "    model.eval() # set model to evaluate mode to deactivate generalizing operations such as dropout and leverage full model\n",
    "    with torch.no_grad(): # turn off gradient tracking and calculation for computational efficiency\n",
    "        for images, labels in data_loader: # cycle through validate data to observe performance\n",
    "            images, labels = images.to(device), labels.to(device) # move data to GPU\n",
    "\n",
    "            log_out = model(images) # obtain the logarithmic probability from the model\n",
    "            loss = criterion(log_out, labels) # calculate loss (error) for this image batch based on criterion\n",
    "            epoch_valid_loss += loss.item() # add validate loss to total valid loss this epoch, convert to value with .item()\n",
    "\n",
    "            out = torch.exp(log_out) # obtain probability from the logarithmic probability calculated by the model\n",
    "            highest_prob, chosen_class = out.topk(1, dim=1) # obtain the chosen classes based on greavalid calculated probability\n",
    "            equals = chosen_class.view(labels.shape) == labels # determine how many correct matches were made in this batch\n",
    "            epoch_count_correct += equals.sum()  # add the count of correct matches this batch to the total running this epoch\n",
    "\n",
    "        ave_validate_loss = epoch_valid_loss / len(data_loader) # determine average loss per batch of validate images\n",
    "\n",
    "    return epoch_count_correct, ave_validate_loss\n",
    "\n",
    "\n",
    "def o4_control_model_grad(model, control=False):\n",
    "    network_depth = len(list(model.children()))\n",
    "    param_freeze_depth = network_depth // 2\n",
    "    controlled_layers = []\n",
    "    layer_depth = 0\n",
    "\n",
    "    for layer in model.children():\n",
    "        layer_depth += 1\n",
    "        if (network_depth - param_freeze_depth) < layer_depth < network_depth:\n",
    "            controlled_layers.append(layer._get_name())\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = control\n",
    "    print(f'\\n Toggle requires_grad = {control}: ', controlled_layers, '\\n')\n",
    "    return model\n",
    "\n",
    "\n",
    "def o5_plot_training_history(model_name, model_hyperparameters):\n",
    "    plt.clf()\n",
    "    plt.plot(model_hyperparameters['training_loss_history'], label='Training Training Loss')\n",
    "    plt.plot(model_hyperparameters['validate_loss_history'], label='Validate Training Loss')\n",
    "    if model_hyperparameters['epoch_on']:\n",
    "        plt.vlines(\n",
    "            colors = 'black',\n",
    "            x = model_hyperparameters['epoch_on'],\n",
    "            ymin = min(model_hyperparameters['training_loss_history']),\n",
    "            ymax = max(model_hyperparameters['training_loss_history'][3:]),\n",
    "            linestyles = 'dotted',\n",
    "            label = 'Deep Layers Activated'\n",
    "        ).set_clip_on(False)\n",
    "        plt.vlines(\n",
    "            colors = 'black',\n",
    "            x = (model_hyperparameters['epoch_on'] + model_hyperparameters['running_count']),\n",
    "            ymin = min(model_hyperparameters['training_loss_history']),\n",
    "            ymax = max(model_hyperparameters['training_loss_history'][3:]),\n",
    "            linestyles = 'dotted',\n",
    "            label = 'Deep Layers Deactivated'\n",
    "        ).set_clip_on(False)\n",
    "    plt.title(model_name)\n",
    "    plt.ylabel('Total Loss')\n",
    "    plt.xlabel('Total Epoch ({})'.format(len(model_hyperparameters['training_loss_history'])))\n",
    "    plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f122f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cnn_model_functions import *\n",
    "\n",
    "# Store a dictionary of available models as names to avoid downloading models until a choice has been made\n",
    "model_name_dic = {'vgg': 'vgg16', 'alexnet': 'alexnet', 'googlenet': 'googlenet', 'densenet': 'densenet161',\n",
    "                    'resnext': 'resnext50_32x4d', 'shufflenet': 'shufflenet_v2_x1_0'}\n",
    "\n",
    "\n",
    "#Create a Classifier class, inheriting from nn.Module and incorporating Relu, Dropout and log_softmax\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_features, hidden_layers, out_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.out_features = out_features\n",
    "        self.layer = 1\n",
    "        while self.layer < self.hidden_layers:\n",
    "            setattr(self, 'fc'+str(self.layer), nn.Linear(round(self.in_features/(2**(self.layer-1))), round(self.in_features/(2**self.layer))))\n",
    "            self.layer += 1\n",
    "        setattr(self, 'fc'+str(self.layer), nn.Linear(round(self.in_features/(2**(self.layer-1))), self.out_features))\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        self.layer = 1\n",
    "        while self.layer < self.hidden_layers:\n",
    "            x = self.dropout(F.relu(getattr(self,'fc'+str(self.layer))(x)))\n",
    "            self.layer += 1\n",
    "        \n",
    "        x = F.log_softmax(getattr(self,'fc'+str(self.layer))(x), dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def m1_create_classifier(model_name, hidden_layers, classes_length):\n",
    "\n",
    "    #Download a pretrained convolutional neural network to reference, choose only the model requested by the user\n",
    "    model = getattr(models, model_name_dic[model_name])(pretrained=True)\n",
    "    #     print(model)\n",
    "    \n",
    "    # Ensure that the in and out features for our model seamlessly match the in from the pretrained CNN and the out for the classes\n",
    "    # Rename the pretrained output layer to a default name 'new_output'\n",
    "    # pretrained_output_name = list(model._modules.items())[-1][0]\n",
    "    # model._modules['new_output'] = model._modules.pop(pretrained_output_name)\n",
    "    out_features = classes_length\n",
    "    for module in list(model.modules()):\n",
    "        if module._get_name() == 'Linear':\n",
    "            in_features = module.weight.shape[1]\n",
    "            break\n",
    "            \n",
    "#     in_features = list(model.children())[-1].weight.shape[1]\n",
    "\n",
    "#     model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "\n",
    "#     Freeze parameters so we don't backprop through them\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    setattr(model, list(model._modules.items())[-1][0], Classifier(in_features, hidden_layers, out_features))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def m2_save_model_checkpoint(model, file_name_scheme, model_hyperparameters):\n",
    "    #Save the model state_dict\n",
    "    torch.save(model.state_dict(), file_name_scheme + '_dict.pth')\n",
    "\n",
    "    #Create a JSON file containing the saved information above\n",
    "    with open(file_name_scheme + '_hyperparameters.json', 'w') as file:\n",
    "        json.dump(model_hyperparameters, file)\n",
    "\n",
    "\n",
    "def m3_load_model_checkpoint(model, file_name_scheme):\n",
    "    # Option to reload from previous state\n",
    "    checkpoint = torch.load(file_name_scheme + '_dict.pth')\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    with open(file_name_scheme + '_hyperparameters.json', 'r') as file:\n",
    "        model_hyperparameters = json.load(file)\n",
    "\n",
    "    print('loaded model learnrate = ', model_hyperparameters['learnrate'])\n",
    "\n",
    "    return model, model_hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ccc3879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def o6_predict_data(model, image_path, topk=5):\n",
    "    ''' Compute probabilities for various classes for an image using a trained deep learning model.\n",
    "    '''\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_image = get_image(image_path)\n",
    "        prediction = torch.exp(model(input_image))\n",
    "        probabilities, classes = prediction.topk(topk)\n",
    "    return probabilities, classes\n",
    "\n",
    "def u7_get_image(image_path):\n",
    "    ''' Process raw image for input to deep learning model\n",
    "    '''\n",
    "    image_open = Image.open(image_path) # access image at pathway, open the image and store it as a PIL image\n",
    "    tensor_image = flower_transform(image_open) # transform PIL image and simultaneously convert image to a tensor (no need for .clone().detach())\n",
    "    input_image = torch.unsqueeze(tensor_image, 0) # change image shape from a stand alone image tensor, to a list of image tensors with length = 1\n",
    "    return input_image # return processed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cf4272d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'models_transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9300/4209267288.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Get processed data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdict_datasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_labels_dic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu2_load_processed_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdict_data_loaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu4_data_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_datasets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9300/1599723183.py\u001b[0m in \u001b[0;36mu2_load_processed_data\u001b[1;34m(data_dir)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m''\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'predict'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0mdict_datasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfolder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_data'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mu3_process_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m''\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'predict'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mpredict_transform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu3_process_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9300/1599723183.py\u001b[0m in \u001b[0;36mu3_process_data\u001b[1;34m(transform_request)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0moverfit_transform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtransform_request\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_transform'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'models_transform'"
     ]
    }
   ],
   "source": [
    "# Record start time\n",
    "start_program_time = time.time()\n",
    "\n",
    "# Get processed data\n",
    "dict_datasets, data_labels_dic, dict_labels = u2_load_processed_data(argdir)\n",
    "dict_data_loaders = u4_data_iterator(dict_datasets)\n",
    "\n",
    "#Create file pathway for hyperparameter saving to JSON format later\n",
    "file_name_scheme = os.path.basename(os.path.dirname(argdir)) + '_' + argmodel\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Download a classifer model for use\n",
    "model = m1_create_classifier(argmodel, arglayer, len(dict_datasets['train_data'].classes))\n",
    "\n",
    "# if argtrain == 'y':\n",
    "# if u5_time_limited_input('Check model can overfit small dataset'):\n",
    "overfit_model, model_hyperparameters = o1_train_model(model, dict_data_loaders, argepoch, arglearn, 'overfit_loader', criterion)\n",
    "o5_plot_training_history(argmodel, model_hyperparameters)\n",
    "plt.savefig(file_name_scheme + '_training_history_overfit.png')\n",
    "print('Saved overfit training history to project directory')\n",
    "\n",
    "# if u5_time_limited_input('Continue with complete model training'):\n",
    "#     model, model_hyperparameters = o1_train_model(model, dict_data_loaders, argepoch, 'train_loader', criterion)\n",
    "#     o5_plot_training_history(argmodel, model_hyperparameters)\n",
    "#     plt.savefig(file_name_scheme + '_training_history_complete.png')\n",
    "#     print('Saved complete training history to project directory')\n",
    "\n",
    "#     if u5_time_limited_input('Would you like to test the model'):\n",
    "t1 = time.time()\n",
    "test_count_correct, ave_test_loss = o3_model_no_backprop(model, dict_data_loaders['testing_loader'], criterion)\n",
    "print('testing Loss: {:.3f}.. '.format(ave_test_loss),\n",
    "    'testing Accuracy: {:.3f}'.format(test_count_correct / len(dict_data_loaders['testing_loader'].dataset)),\n",
    "    'Runtime - {:.0f} seconds'.format((time.time() - t1)))\n",
    "\n",
    "#     #Save the model hyperparameters and the locations in which the CNN training activated and deactivated\n",
    "#     if u5_time_limited_input('Would you like to save the model'):\n",
    "#         m2_save_model_checkpoint(model, file_name_scheme, model_hyperparameters)\n",
    "\n",
    "# if argtrain == 'n':\n",
    "#     model, model_hyperparameters = m3_load_model_checkpoint(model, file_name_scheme)\n",
    "#     o5_plot_training_history(argmodel, model_hyperparameters)\n",
    "#     plt.show(block=False)\n",
    "#     plt.pause(3)\n",
    "#     plt.close()\n",
    "\n",
    "#     learnrate = model_hyperparameters['learnrate']\n",
    "#     training_loss_history = model_hyperparameters['training_loss_history']\n",
    "#     validate_loss_history = model_hyperparameters['validate_loss_history']\n",
    "#     epoch_on = model_hyperparameters['epoch_on']\n",
    "#     running_count = model_hyperparameters['running_count']\n",
    "\n",
    "#     print('The model is ready to provide predictions')\n",
    "\n",
    "    #\n",
    "    # o6_predict_data():\n",
    "    #\n",
    "    # u7_show_prediction():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a106f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'fromkeys',\n",
       " 'get',\n",
       " 'items',\n",
       " 'keys',\n",
       " 'pop',\n",
       " 'popitem',\n",
       " 'setdefault',\n",
       " 'update',\n",
       " 'values']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameters = {'training_loss_history': [],\n",
    "                     'validate_loss_history': [],\n",
    "                     'epoch_on': [],\n",
    "                     'running_count': 0,\n",
    "                     'weightdecay' : 0.00001,\n",
    "                     'training_time' : 0}\n",
    "'_training_history_overfit.png'\n",
    "dir(model_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19758f49",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9300/730765719.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Troubleshooter on param layer depth search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnetwork_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mparam_freeze_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork_depth\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcontrol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Troubleshooter on param layer depth search\n",
    "network_depth = len(list(model.children()))\n",
    "param_freeze_depth = network_depth // 2\n",
    "control = False\n",
    "\n",
    "controlled_layers = []\n",
    "layer_depth = 0\n",
    "\n",
    "for layer in model.children():\n",
    "    print(layer._get_name())\n",
    "    layer_depth += 1\n",
    "#     print(f'network_depth - param_freeze_depth = {network_depth - param_freeze_depth} < layer_depth = {layer_depth} < network_depth = {network_depth}')\n",
    "    if (network_depth - param_freeze_depth) < layer_depth < network_depth:\n",
    "        controlled_layers.append(layer._get_name())\n",
    "#         for param in layer.parameters():\n",
    "#             param.requires_grad = control\n",
    "\n",
    "print(f'\\n Toggle requires_grad = {control}: ', controlled_layers, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e93b958",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'models_transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9300/4188112397.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get processed data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdict_datasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_labels_dic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_class_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu2_load_processed_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdict_data_loaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu4_data_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_datasets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0margmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'googlenet'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9300/1599723183.py\u001b[0m in \u001b[0;36mu2_load_processed_data\u001b[1;34m(data_dir)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m''\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'predict'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0mdict_datasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfolder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_data'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mu3_process_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m''\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'predict'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mpredict_transform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu3_process_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9300/1599723183.py\u001b[0m in \u001b[0;36mu3_process_data\u001b[1;34m(transform_request)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0moverfit_transform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtransform_request\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_transform'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'models_transform'"
     ]
    }
   ],
   "source": [
    "# Get processed data\n",
    "dict_datasets, data_labels_dic, dict_class_labels = u2_load_processed_data(argdir)\n",
    "dict_data_loaders = u4_data_iterator(dict_datasets)\n",
    "\n",
    "argmodel = 'googlenet'\n",
    "# argmodel = 'alexnet'\n",
    "# argmodel = 'vgg'\n",
    "arglayer = 3\n",
    "model = m1_create_classifier(argmodel, arglayer, len(dict_datasets['train_data'].classes))\n",
    "\n",
    "# model\n",
    "# print(list(model.children())[-1])\n",
    "\n",
    "# list(model._modules.items())\n",
    "# list(model.children())\n",
    "# list(model.children())[-1]\n",
    "# .weight.shape[1]\n",
    "\n",
    "# in_features = list(model.children())[-1][1].weight.shape[1]\n",
    "# list(model._modules.items())[-1][0]\n",
    "\n",
    "image_1d_size = 224\n",
    "predict_transform = transforms.Compose([transforms.Resize(int(np.round_(image_1d_size*1.1, decimals=0))),\n",
    "                                            transforms.CenterCrop(image_1d_size),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "# plt.imshow(random.choice(dict_datasets['test_data'])[0].numpy().transpose((1, 2, 0)))\n",
    "\n",
    "\n",
    "image_open = Image.open(dict_datasets['test_data'].imgs[0][0])\n",
    "image_tensor = predict_transform(image_open)\n",
    "# image_tensor\n",
    "# plt.imshow(dict_datasets['test_data'][0].numpy().transpose((1, 2, 0)))\n",
    "# torch.unsqueeze(image_tensor, 0)\n",
    "dict_datasets['test_data'].imgs[0][0]\n",
    "dict_datasets['test_data']\n",
    "dict_data_loaders['testing_loader']\n",
    "# t = u3_process_data('predict')(Image.open(argdir + 'predict'))\n",
    "\n",
    "# dir(dict_data_loaders['train_loader'].dataset)\n",
    "os.path.basename(dict_data_loaders['train_loader'].dataset.root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c5c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ad036ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'models_transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9300/3643554151.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdict_datasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_data_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_class_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu2_load_processed_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpredict_transform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu3_process_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdict_datasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predict_data'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margdir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'predict/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margdir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'predict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdict_data_loaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predict_loader'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_datasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predict_data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9300/1599723183.py\u001b[0m in \u001b[0;36mu2_load_processed_data\u001b[1;34m(data_dir)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m''\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'predict'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0mdict_datasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfolder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_data'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mu3_process_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m''\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'predict'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mpredict_transform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu3_process_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9300/1599723183.py\u001b[0m in \u001b[0;36mu3_process_data\u001b[1;34m(transform_request)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0moverfit_transform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtransform_request\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_transform'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'models_transform'"
     ]
    }
   ],
   "source": [
    "dict_datasets, dict_data_labels, dict_class_labels = u2_load_processed_data(argdir)\n",
    "predict_transform = u3_process_data('predict')\n",
    "\n",
    "dict_datasets['predict_data'] = [(predict_transform(Image.open(argdir + 'predict/' + filename)), filename) for filename in os.listdir(argdir + 'predict')]\n",
    "dict_data_loaders['predict_loader'] = torch.utils.data.DataLoader(dict_datasets['predict_data'], batch_size=2, shuffle=False)\n",
    "\n",
    "\n",
    "name = 'balloonflower.jpeg'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval() \n",
    "results_dic = {}\n",
    "with torch.no_grad(): # turn off gradient tracking and calculation for computational efficiency\n",
    "    for image, filenames in dict_data_loaders['predict_loader']:\n",
    "        image = image.to(device)\n",
    "        model_output = torch.exp(model(image))\n",
    "        probabilities, class_indexes = model_output.topk(5, dim=1)\n",
    "        print(np.arange(len(filenames)))\n",
    "        for index in np.arange(len(filenames)):\n",
    "            print(index)\n",
    "            class_prediction = [data_labels_dic[dict_class_labels[value]] for value in class_indexes.tolist()[index]]\n",
    "            results_dic[filenames[index]] = [class_prediction, probabilities.tolist()[index]]\n",
    "            \n",
    "        \n",
    "\n",
    "print(results_dic['balloonflower.jpeg'])\n",
    "                    \n",
    "#         classes = [dict_class_labels[image[key]] for image, key in class_indexes[key]]\n",
    "#         for \n",
    "#         print(classes)\n",
    "#         dict_class_labels[np.array(classes.cpu())[i]] for i in np.array(classes.cpu())])\n",
    "        \n",
    "#         for prediction in np.array(classes.cpu()[0]):\n",
    "#             results_dic[filename] = [probabilities.cpu()[0].tolist(), [dict_data_labels[str(index)]]\n",
    "        \n",
    "print(results_dic)\n",
    "\n",
    "# prediction = torch.exp(model(game_images)) \n",
    "# highest_prob, predicted_class = prediction.topk(1, dim=1)\n",
    "\n",
    "\n",
    "# flower_prediction = []\n",
    "# for predicted_flower in predicted_class:\n",
    "#     flower_prediction.append([key for key, value in game_data.class_to_idx.items() if value == predicted_flower]) \n",
    "# flower_answer = []\n",
    "# for correct_flower in game_labels:\n",
    "#     flower_answer.append([key for key, value in game_data.class_to_idx.items() if value == correct_flower])   \n",
    "\n",
    "# print('Left: \\033[1m{}\\033[0m and Right: \\033[1m{}\\033[0m'.format(flower_name_dic[flower_prediction[0][0]], flower_name_dic[flower_prediction[1][0]]))\n",
    "\n",
    "example_prediction = random.choice(list(results_dic.keys()))\n",
    "\n",
    "plt.imshow(Image.open(argdir + 'predict/' + name)); # no need to process and inverse transform, our data is coming from the same path, I'll just open the original\n",
    "plt.show()\n",
    "plt.bar(results_dic[name][0], results_dic[name][1])\n",
    "plt.xticks(rotation=20);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b95e5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1050'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e687f598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9300/3328039166.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnetwork_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mparam_freeze_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork_depth\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcontrolled_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlayer_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcontrol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "network_depth = len(list(model.modules()))\n",
    "param_freeze_depth = network_depth // 3\n",
    "controlled_layers = []\n",
    "layer_depth = 0\n",
    "control = True\n",
    "params_to_update = []\n",
    "\n",
    "for layer in list(model.modules()):\n",
    "    layer_depth += 1\n",
    "    print(layer._get_name())\n",
    "    if (network_depth - param_freeze_depth) <= layer_depth and layer._get_name() != 'Linear':\n",
    "        controlled_layers.append(layer._get_name())\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = control\n",
    "            params_to_update.append(param)\n",
    "    if layer._get_name() == 'Linear' and control:\n",
    "        for param in layer.parameters():\n",
    "            params_to_update.append(param)\n",
    "\n",
    "# optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=model_hyperparameters['learnrate'], weight_decay=model_hyperparameters['weightdecay'])      \n",
    "optimizer = optim.Adam(params_to_update, lr=model_hyperparameters['learnrate'], weight_decay=model_hyperparameters['weightdecay'])      \n",
    "   \n",
    "print(f'\\n Toggle requires_grad = {control}: ', controlled_layers, '\\n')\n",
    "print(len(list(model.modules())))\n",
    "print(len(controlled_layers))\n",
    "\n",
    "# params_to_update = []\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.requires_grad == True:\n",
    "#         params_to_update.append(param)\n",
    "# optimizer = optim.Adam(params_to_update, lr = 0.001)\n",
    "# print(list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22228907",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(model.children())))\n",
    "print(len(list(model.modules())))\n",
    "print('Using GPU =', torch.cuda.get_device_name() if torch.cuda.is_available() else \"WARNING GPU UNAVAILABLE\")\n",
    "print(np.around(torch.cuda.memory_allocated()*(10**-9), decimals=2), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63b7736",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_depth = len(list(model.children()))\n",
    "param_freeze_depth = network_depth // 3\n",
    "controlled_layers = []\n",
    "layer_depth = 0\n",
    "control=True\n",
    "\n",
    "for layer in model.children():\n",
    "    layer_depth += 1\n",
    "    print(layer._get_name())\n",
    "    if (network_depth - param_freeze_depth) < layer_depth and layer._get_name() not in ['Classifier','Linear', 'Dropout']:\n",
    "        controlled_layers.append(layer._get_name())\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = control\n",
    "        \n",
    "print(f'\\n Toggle requires_grad = {control}: ', controlled_layers, '\\n')\n",
    "print(len(list(model.children())))\n",
    "print(len(controlled_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c7b2cb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9300/1329177898.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                          'weightdecay' : 0.00001}\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m optimizer = optim.Adam(getattr(model, list(model._modules.items())[-1][0]).parameters(),\n\u001b[0m\u001b[0;32m      9\u001b[0m                                 lr=model_hyperparameters['learnrate'], weight_decay=model_hyperparameters['weightdecay'])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model_hyperparameters = {'learnrate': 0.003,\n",
    "                         'training_loss_history': [],\n",
    "                         'validate_loss_history': [],\n",
    "                         'epoch_on': [],\n",
    "                         'running_count': 0,\n",
    "                         'weightdecay' : 0.00001}\n",
    "\n",
    "optimizer = optim.Adam(getattr(model, list(model._modules.items())[-1][0]).parameters(),\n",
    "                                lr=model_hyperparameters['learnrate'], weight_decay=model_hyperparameters['weightdecay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f315406b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9300/3070682692.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "dir(optimizer)\n",
    "optimizer.param_groups\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "optimizer = optim.Adam(model.parameters(), lr=model_hyperparameters['learnrate'], weight_decay=model_hyperparameters['weightdecay'])\n",
    "dir(optimizer)\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=model_hyperparameters['learnrate'], weight_decay=model_hyperparameters['weightdecay'])      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9c087d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9300/2682295716.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "getattr(model, list(model._modules.items())[-1][0]).state_dict().keys()\n",
    "list(model._modules.items())[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2046a067",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dict_data_loaders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9300/2494666570.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_data_loaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'testing_loader'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_data_loaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_loader'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dict_data_loaders' is not defined"
     ]
    }
   ],
   "source": [
    "len(dict_data_loaders['testing_loader'].dataset)\n",
    "len(dict_data_loaders['train_loader'].dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c26226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e060b992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
