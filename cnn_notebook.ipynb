{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "164be129",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time, os, random\n",
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch import nn, optim\n",
    "from PIL import Image\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c6ec94d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "argtrain = 'y'\n",
    "argepoch = 100\n",
    "argmodel = 'googlenet'\n",
    "arglabel = 'flower_to_name.json'\n",
    "argdir = os.path.expanduser('~') + '/Programming Data/Flower_data/'\n",
    "\n",
    "# 'vgg', 'alexnet', 'googlenet', 'densenet', 'inception', 'resnext', 'shufflenet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c4b7ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cnn_utility_functions import *\n",
    "\n",
    "def u1_get_input_args():\n",
    "    \"\"\"\n",
    "    Creates and stores command line arguments inputted by the user. Attaches default arguments and help text to aid user.\n",
    "    Command Line Arguments:\n",
    "        1. Directory as --dir\n",
    "        2. CNN Model as --model\n",
    "        3. Data Name Dictionary as --names\n",
    "    This function returns these arguments as an ArgumentParser object.\n",
    "    Parameters:\n",
    "        - None\n",
    "    Returns:\n",
    "        - Stored command line arguments as an Argument Parser Object with parse_args() data structure\n",
    "    \"\"\"\n",
    "\n",
    "    parser = argparse.ArgumentParser(description = 'Classify input images and benchmark performance')\n",
    "    parser.add_argument('--dir', type=str, default= os.path.expanduser('~')+'/Programming Data/Flower_data/', help='input path for data directory')\n",
    "    parser.add_argument('--train', type=str, default='n', help='yes \\'y\\' or no \\'n\\' to retrain this model', choices=['y','n'])\n",
    "    parser.add_argument('--epoch', type=str, default=100, help='provide the number of epochs for training (default 100)')\n",
    "    parser.add_argument('--label', type=str, default='', help='flower_to_name.json')\n",
    "    parser.add_argument('--model', type=str, default='googlenet', help='select pretrained model', choices=['vgg', 'alexnet', 'googlenet',\n",
    "                        'densenet', 'inception', 'resnext', 'shufflenet'])\n",
    "\n",
    "    return parser.parse_args() #return parsed arguments\n",
    "\n",
    "\n",
    "def u2_load_processed_data(data_dir):\n",
    "    \"\"\"\n",
    "    Receives a pathway to a folder containing training, .\n",
    "    Command Line Arguments:\n",
    "        1. Directory as --dir\n",
    "        2. CNN Model as --model\n",
    "        3. Data Name Dictionary as --names\n",
    "    This function returns these arguments as an ArgumentParser object.\n",
    "    Parameters:\n",
    "        - None\n",
    "    Returns:\n",
    "        - Stored command line arguments as an Argument Parser Object with parse_args() data structure\n",
    "    \"\"\"\n",
    "\n",
    "    dict_datasets = {}\n",
    "    for folder in os.listdir(data_dir):\n",
    "        if os.path.splitext(folder)[1] == '' and folder != 'predict':\n",
    "            dict_datasets[folder + '_data'] = datasets.ImageFolder(data_dir + folder, transform=u3_process_data(folder))\n",
    "        if os.path.splitext(folder)[1] == '.json':\n",
    "            with open(data_dir + folder, 'r') as f:\n",
    "                data_labels_dic = json.load(f)\n",
    "                data_labels_dic = {value : key for (key, value) in data_labels_dic.items()}\n",
    "    return dict_datasets, data_labels_dic\n",
    "\n",
    "\n",
    "def u3_process_data(transform_request):\n",
    "    #Define transforms for training, validation, overfitting, and test sets to convert to desirable tensors for processing\n",
    "\n",
    "    #Define image size\n",
    "    image_1d_size = 224\n",
    "\n",
    "    predict_transform = transforms.Compose([transforms.Resize(int(np.round_(image_1d_size*1.1, decimals=0))),\n",
    "                                            transforms.CenterCrop(image_1d_size),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    inverse_transform = transforms.Compose([transforms.Normalize([0, 0, 0], [1/0.229, 1/0.224, 1/0.225]),\n",
    "                                            transforms.Normalize([-0.485, -0.456, -0.406], [1, 1, 1])])\n",
    "\n",
    "    train_transform = transforms.Compose([transforms.RandomRotation(20),\n",
    "                                          transforms.RandomResizedCrop(image_1d_size),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "\n",
    "    valid_transform = transforms.Compose([transforms.Resize(int(np.round_(image_1d_size*1.1, decimals=0))),\n",
    "                                          transforms.CenterCrop(image_1d_size),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    test_transform = transforms.Compose([transforms.Resize(int(np.round_(image_1d_size*1.1, decimals=0))),\n",
    "                                         transforms.CenterCrop(image_1d_size),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    game_transform = transforms.Compose([transforms.Resize(int(np.round_(image_1d_size*1.1, decimals=0))),\n",
    "                                         transforms.CenterCrop(image_1d_size),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "    overfit_transform = train_transform\n",
    "\n",
    "    return locals()[transform_request + '_transform']\n",
    "\n",
    "\n",
    "def u4_data_iterator(dict_datasets):\n",
    "    '''\n",
    "    # bug, requires every folder to run correctly. Consider removing this function and nesting it directly into training function!\n",
    "    '''\n",
    "    dict_data_loaders = {}\n",
    "    dict_data_loaders['train_loader'] = torch.utils.data.DataLoader(dict_datasets['train_data'], batch_size=128, shuffle=True)\n",
    "    dict_data_loaders['valid_loader'] = torch.utils.data.DataLoader(dict_datasets['valid_data'], batch_size=64, shuffle=True)\n",
    "    dict_data_loaders['testing_loader'] = torch.utils.data.DataLoader(dict_datasets['test_data'], batch_size=32, shuffle=True)\n",
    "    dict_data_loaders['overfit_loader'] = torch.utils.data.DataLoader(dict_datasets['overfit_data'], batch_size=8, shuffle=True)\n",
    "\n",
    "    return dict_data_loaders\n",
    "\n",
    "\n",
    "def u5_time_limited_input(prompt):\n",
    "    TIMEOUT = 10\n",
    "    prompt = prompt + f': \\'y\\' for yes, \\'n\\' for no ({TIMEOUT} seconds to choose): '\n",
    "    user_input_thread = Thread(target=u6_user_input_prompt, args=(prompt,), daemon = True)\n",
    "    user_input_thread.start()\n",
    "    user_input_thread.join(TIMEOUT)\n",
    "    if not answered:\n",
    "        print('\\n No valid input, proceeding with operation...')\n",
    "    return choice\n",
    "\n",
    "\n",
    "def u6_user_input_prompt(prompt, default=True):\n",
    "    global choice, answered\n",
    "    choice = default\n",
    "    answered = False\n",
    "    while not answered:\n",
    "        choice = input(prompt)\n",
    "        if choice == 'Y' or choice == 'y':\n",
    "            print('User input = Yes\\n')\n",
    "            choice = True\n",
    "            answered = True\n",
    "        elif choice == 'N' or choice == 'n':\n",
    "            choice = False\n",
    "            answered = True\n",
    "            print('User input = No\\n')\n",
    "        else:\n",
    "            choice=choice\n",
    "            print('Error, please use the character inputs \\'Y\\' and \\'N\\'')\n",
    "\n",
    "\n",
    "# def u7_get_image(image_path):\n",
    "#     ''' Process raw image for input to deep learning model\n",
    "#     '''\n",
    "#     image_open = Image.open(image_path) # access image at pathway, open the image and store it as a PIL image\n",
    "#     tensor_image = flower_transform(image_open) # transform PIL image and simultaneously convert image to a tensor (no need for .clone().detach())\n",
    "#     input_image = torch.unsqueeze(tensor_image, 0) # change image shape from a stand alone image tensor, to a list of image tensors with length = 1\n",
    "#     return input_image # return processed image\n",
    "\n",
    "\n",
    "# def u8_show_image():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "67c90468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From cnn_operational_functions.py import *\n",
    "\n",
    "def o1_train_model(model, dict_data_loaders, epoch, type_loader, criterion):\n",
    "\n",
    "    print(\"Using GPU\" if torch.cuda.is_available() else \"WARNING\")\n",
    "    t0 = time.time() # initialize start time for running training\n",
    "\n",
    "    running_count = 0 # initialize running count in order to track number of epochs fine tuning deeper network\n",
    "    running = False # initialize running variable to start system with deeper network frozen\n",
    "\n",
    "    # Define default hyperparameters: learning rate and weight decay\n",
    "    model_hyperparameters = {'learnrate': 0.003,\n",
    "                         'training_loss_history': [],\n",
    "                         'validate_loss_history': [],\n",
    "                         'epoch_on': [],\n",
    "                         'running_count': 0,\n",
    "                         'weightdecay' : 0.00001}\n",
    "\n",
    "    startlearn = model_hyperparameters['learnrate']\n",
    "\n",
    "    # Only train the classifier (new_output) parameters, feature parameters are frozen\n",
    "    optimizer = optim.Adam(getattr(model, list(model._modules.items())[-1][0]).parameters(), lr=model_hyperparameters['learnrate'], weight_decay=model_hyperparameters['weightdecay'])\n",
    "\n",
    "    if type_loader == 'overfit_loader':\n",
    "        decay = 0.9 # hyperparameter decay factor for decaying learning rate\n",
    "        epoch = 200 # hyperparameter number of epochs\n",
    "\n",
    "    if type_loader == 'train_loader':\n",
    "        decay = 0.6 # hyperparameter decay factor for decaying learning rate\n",
    "\n",
    "    for e in range(epoch):\n",
    "\n",
    "        model, ave_training_loss = o2_model_backprop(model, dict_data_loaders[type_loader], optimizer, criterion)\n",
    "        epoch_count_correct, ave_validate_loss = o3_model_no_backprop(model, dict_data_loaders['valid_loader'], criterion)\n",
    "\n",
    "        model_hyperparameters['training_loss_history'].append(ave_training_loss) # append ave training loss to history of training losses\n",
    "        model_hyperparameters['validate_loss_history'].append(ave_validate_loss) # append ave validate loss to history of validate losses\n",
    "\n",
    "        print('Epoch: {}/{}.. '.format(e+1, epoch),\n",
    "            'Train Loss: {:.3f}.. '.format(ave_training_loss),\n",
    "            'Valid Loss: {:.3f}.. '.format(ave_validate_loss),\n",
    "            'Valid Accuracy: {:.3f}.. '.format(epoch_count_correct / len(dict_data_loaders['valid_loader'].dataset)),\n",
    "            'Runtime - {:.0f} mins'.format((time.time() - t0)/60))\n",
    "\n",
    "        training_loss_history = model_hyperparameters['training_loss_history']\n",
    "        if len(training_loss_history) > 3: # hold loop until training_loss_history has enough elements to satisfy search requirements\n",
    "            if -3*model_hyperparameters['learnrate']*decay*decay*training_loss_history[0] > np.mean([training_loss_history[-2]-training_loss_history[-1], training_loss_history[-3]-training_loss_history[-2]]):\n",
    "                # if the average of the last 2 training loss slopes is less than the original loss factored down by the learnrate, the decay, and a factor of 3, then decay the learnrate\n",
    "                model_hyperparameters['learnrate'] *= decay # multiply learnrate by the decay hyperparameter\n",
    "                optimizer = optim.Adam(getattr(model, list(model._modules.items())[-1][0]).parameters(), lr=model_hyperparameters['learnrate'], weight_decay=model_hyperparameters['weightdecay']) # revise the optimizer to use the new learnrate\n",
    "                print('Learnrate changed to: {:f}'.format(model_hyperparameters['learnrate']))\n",
    "            if model_hyperparameters['learnrate'] <= startlearn*decay**(9*(decay**3)) and model_hyperparameters['running_count'] == 0: # super messy, I wanted a general expression that chose when to activate the deeper network and this worked\n",
    "                model = o4_control_model_grad(model, True)\n",
    "                model_hyperparameters['epoch_on'] = e\n",
    "                running = True # change the running parameter to True so that the future loop can start counting epochs that have run\n",
    "            if running: # if running, add to count for the number of epochs run\n",
    "                model_hyperparameters['running_count'] +=1\n",
    "            if running and model_hyperparameters['running_count'] > epoch/5: # deactivate parameters if running, add the count has reached its limiter\n",
    "                model = o4_control_model_grad(model, False)\n",
    "                running = False\n",
    "            if type_loader == 'overfit_loader':\n",
    "                if np.mean([training_loss_history[-1], training_loss_history[-2], training_loss_history[-3]]) < 0.0002:\n",
    "                    print('\\nModel successfully overfit images\\n')\n",
    "                    return model, model_hyperparameters\n",
    "                if e+1 == epoch:\n",
    "                    print('\\nModel failed to overfit images\\n')\n",
    "\n",
    "    return model, model_hyperparameters\n",
    "\n",
    "\n",
    "def o2_model_backprop(model, data_loader, optimizer, criterion):\n",
    "    # Check model can overfit the data when using a miniscule sample size, looking for high accuracy on a few images\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.cuda.empty_cache()\n",
    "    model.to(device)\n",
    "\n",
    "    epoch_train_loss = 0 # initialize total training loss for this epoch\n",
    "    model.train() # Set model to training mode to activate operations such as dropout\n",
    "    for images, labels in data_loader: # cycle through training data\n",
    "        images, labels = images.to(device), labels.to(device) # move data to GPU\n",
    "\n",
    "        optimizer.zero_grad() # clear gradient history\n",
    "        log_out = model(images) # run image through model to get logarithmic probability\n",
    "        loss = criterion(log_out, labels) # calculate loss (error) for this image batch based on criterion\n",
    "\n",
    "        loss.backward() # backpropogate gradients through model based on error\n",
    "        optimizer.step() # update weights in model based on calculated gradient information\n",
    "        epoch_train_loss += loss.item() # add training loss to total train loss this epoch, convert to value with .item()\n",
    "    ave_training_loss = epoch_train_loss / len(data_loader) # determine average loss per batch of training images\n",
    "\n",
    "    return model, ave_training_loss\n",
    "\n",
    "\n",
    "def o3_model_no_backprop(model, data_loader, criterion):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    epoch_valid_loss = 0 # initialize total validate loss for this epoch\n",
    "    epoch_count_correct = 0 # initialize total correct predictions on valid set\n",
    "    model.eval() # set model to evaluate mode to deactivate generalizing operations such as dropout and leverage full model\n",
    "    with torch.no_grad(): # turn off gradient tracking and calculation for computational efficiency\n",
    "        for images, labels in data_loader: # cycle through validate data to observe performance\n",
    "            images, labels = images.to(device), labels.to(device) # move data to GPU\n",
    "\n",
    "            log_out = model(images) # obtain the logarithmic probability from the model\n",
    "            loss = criterion(log_out, labels) # calculate loss (error) for this image batch based on criterion\n",
    "            epoch_valid_loss += loss.item() # add validate loss to total valid loss this epoch, convert to value with .item()\n",
    "\n",
    "            out = torch.exp(log_out) # obtain probability from the logarithmic probability calculated by the model\n",
    "            highest_prob, chosen_class = out.topk(1, dim=1) # obtain the chosen classes based on greavalid calculated probability\n",
    "            equals = chosen_class.view(labels.shape) == labels # determine how many correct matches were made in this batch\n",
    "            epoch_count_correct += equals.sum()  # add the count of correct matches this batch to the total running this epoch\n",
    "\n",
    "        ave_validate_loss = epoch_valid_loss / len(data_loader) # determine average loss per batch of validate images\n",
    "\n",
    "    return epoch_count_correct, ave_validate_loss\n",
    "\n",
    "\n",
    "def o4_control_model_grad(model, control=False):\n",
    "    network_depth = len(list(model.children()))\n",
    "    param_freeze_depth = network_depth // 2\n",
    "    controlled_layers = []\n",
    "    layer_depth = 0\n",
    "\n",
    "    for layer in model.children():\n",
    "        layer_depth += 1\n",
    "        if (network_depth - param_freeze_depth) < layer_depth < network_depth:\n",
    "            controlled_layers.append(layer._get_name())\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = control\n",
    "    print(f'\\n Toggle requires_grad = {control}: ', controlled_layers, '\\n')\n",
    "    return model\n",
    "\n",
    "\n",
    "def o5_plot_training_history(model_name, model_hyperparameters):\n",
    "    plt.clf()\n",
    "    plt.plot(model_hyperparameters['training_loss_history'], label='Training Training Loss')\n",
    "    plt.plot(model_hyperparameters['validate_loss_history'], label='Validate Training Loss')\n",
    "    if model_hyperparameters['epoch_on']:\n",
    "        plt.vlines(\n",
    "            colors = 'black',\n",
    "            x = model_hyperparameters['epoch_on'],\n",
    "            ymin = min(model_hyperparameters['training_loss_history']),\n",
    "            ymax = max(model_hyperparameters['training_loss_history'][3:]),\n",
    "            linestyles = 'dotted',\n",
    "            label = 'Deep Layers Activated'\n",
    "        ).set_clip_on(False)\n",
    "        plt.vlines(\n",
    "            colors = 'black',\n",
    "            x = (model_hyperparameters['epoch_on'] + model_hyperparameters['running_count']),\n",
    "            ymin = min(model_hyperparameters['training_loss_history']),\n",
    "            ymax = max(model_hyperparameters['training_loss_history'][3:]),\n",
    "            linestyles = 'dotted',\n",
    "            label = 'Deep Layers Deactivated'\n",
    "        ).set_clip_on(False)\n",
    "    plt.title(model_name)\n",
    "    plt.ylabel('Total Loss')\n",
    "    plt.xlabel('Total Epoch ({})'.format(len(model_hyperparameters['training_loss_history'])))\n",
    "    plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f122f4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cnn_model_functions import *\n",
    "\n",
    "# Store a dictionary of available models as names to avoid downloading models until a choice has been made\n",
    "model_name_dic = {'vgg': 'vgg16', 'alexnet': 'alexnet', 'googlenet': 'googlenet', 'densenet': 'densenet161',\n",
    "                    'resnext': 'resnext50_32x4d', 'shufflenet': 'shufflenet_v2_x1_0'}\n",
    "\n",
    "\n",
    "#Create a Classifier class, inheriting from nn.Module and incorporating Relu, Dropout and log_softmax\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.fc1 = nn.Linear(self.in_features, 512)\n",
    "        self.fc2 = nn.Linear(512, self.out_features)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "def m1_create_classifier(model_name, classes_length):\n",
    "\n",
    "    #Download a pretrained convolutional neural network to reference, choose only the model requested by the user\n",
    "    model = getattr(models, model_name_dic[model_name])(pretrained=True)\n",
    "    #     print(model)\n",
    "    \n",
    "    # Ensure that the in and out features for our model seamlessly match the in from the pretrained CNN and the out for the classes\n",
    "    # Rename the pretrained output layer to a default name 'new_output'\n",
    "    # pretrained_output_name = list(model._modules.items())[-1][0]\n",
    "    # model._modules['new_output'] = model._modules.pop(pretrained_output_name)\n",
    "    out_features = classes_length\n",
    "    for module in list(model.modules()):\n",
    "        if module._get_name() == 'Linear':\n",
    "            in_features = module.weight.shape[1]\n",
    "            break\n",
    "            \n",
    "#     in_features = list(model.children())[-1].weight.shape[1]\n",
    "\n",
    "#     model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "\n",
    "#     Freeze parameters so we don't backprop through them\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    setattr(model, list(model._modules.items())[-1][0], Classifier(in_features, out_features))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def m2_save_model_checkpoint(model, file_name_scheme, model_hyperparameters):\n",
    "    #Save the model state_dict\n",
    "    torch.save(model.state_dict(), file_name_scheme + '_dict.pth')\n",
    "    getattr(model, list(model._modules.items())[-1][0]).state_dict().keys()\n",
    "\n",
    "    #Create a JSON file containing the saved information above\n",
    "    with open(file_name_scheme + '_hyperparameters.json', 'w') as file:\n",
    "        json.dump(model_hyperparameters, file)\n",
    "\n",
    "\n",
    "def m3_load_model_checkpoint(model, file_name_scheme):\n",
    "    # Option to reload from previous state\n",
    "    checkpoint = torch.load(file_name_scheme + '_dict.pth')\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    with open(file_name_scheme + '_hyperparameters.json', 'r') as file:\n",
    "        model_hyperparameters = json.load(file)\n",
    "\n",
    "    print('loaded model learnrate = ', model_hyperparameters['learnrate'])\n",
    "\n",
    "    return model, model_hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4e93b958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GoogLeNet(\n",
       "  (conv1): BasicConv2d(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (conv2): BasicConv2d(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): BasicConv2d(\n",
       "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception3a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception3b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception4a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4c): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4d): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4e): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception5a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception5b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (aux1): None\n",
       "  (aux2): None\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Classifier(\n",
       "    (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (fc2): Linear(in_features=512, out_features=102, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "argmodel = 'googlenet'\n",
    "# argmodel = 'alexnet'\n",
    "# argmodel = 'inception'\n",
    "model = m1_create_classifier(argmodel, len(dict_datasets['train_data'].classes))\n",
    "\n",
    "model\n",
    "# list(model._modules.items())\n",
    "# list(model.children())\n",
    "# list(model.children())[-1]\n",
    "# .weight.shape[1]\n",
    "\n",
    "# in_features = list(model.children())[-1][1].weight.shape[1]\n",
    "# list(model._modules.items())[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "19758f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicConv2d\n",
      "network_depth - param_freeze_depth = 10 < layer_depth = 1 < network_depth = 19\n",
      "MaxPool2d\n",
      "network_depth - param_freeze_depth = 10 < layer_depth = 2 < network_depth = 19\n",
      "BasicConv2d\n",
      "network_depth - param_freeze_depth = 10 < layer_depth = 3 < network_depth = 19\n",
      "BasicConv2d\n",
      "network_depth - param_freeze_depth = 10 < layer_depth = 4 < network_depth = 19\n",
      "MaxPool2d\n",
      "network_depth - param_freeze_depth = 10 < layer_depth = 5 < network_depth = 19\n",
      "Inception\n",
      "network_depth - param_freeze_depth = 10 < layer_depth = 6 < network_depth = 19\n",
      "Inception\n",
      "network_depth - param_freeze_depth = 10 < layer_depth = 7 < network_depth = 19\n",
      "MaxPool2d\n",
      "network_depth - param_freeze_depth = 10 < layer_depth = 8 < network_depth = 19\n",
      "Inception\n",
      "network_depth - param_freeze_depth = 10 < layer_depth = 9 < network_depth = 19\n",
      "Inception\n",
      "network_depth - param_freeze_depth = 10 < layer_depth = 10 < network_depth = 19\n",
      "Inception\n",
      "network_depth - param_freeze_depth = 10 < layer_depth = 11 < network_depth = 19\n",
      "Inception\n",
      "network_depth - param_freeze_depth = 10 < layer_depth = 12 < network_depth = 19\n",
      "Inception\n",
      "network_depth - param_freeze_depth = 10 < layer_depth = 13 < network_depth = 19\n",
      "MaxPool2d\n",
      "network_depth - param_freeze_depth = 10 < layer_depth = 14 < network_depth = 19\n",
      "Inception\n",
      "network_depth - param_freeze_depth = 10 < layer_depth = 15 < network_depth = 19\n",
      "Inception\n",
      "network_depth - param_freeze_depth = 10 < layer_depth = 16 < network_depth = 19\n",
      "AdaptiveAvgPool2d\n",
      "network_depth - param_freeze_depth = 10 < layer_depth = 17 < network_depth = 19\n",
      "Dropout\n",
      "network_depth - param_freeze_depth = 10 < layer_depth = 18 < network_depth = 19\n",
      "Classifier\n",
      "network_depth - param_freeze_depth = 10 < layer_depth = 19 < network_depth = 19\n",
      "\n",
      " Toggle requires_grad = False:  ['Inception', 'Inception', 'Inception', 'MaxPool2d', 'Inception', 'Inception', 'AdaptiveAvgPool2d', 'Dropout'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Troubleshooter on param layer depth search\n",
    "network_depth = len(list(model.children()))\n",
    "param_freeze_depth = network_depth // 2\n",
    "control = False\n",
    "\n",
    "controlled_layers = []\n",
    "layer_depth = 0\n",
    "\n",
    "for layer in model.children():\n",
    "    print(layer._get_name())\n",
    "    layer_depth += 1\n",
    "    print(f'network_depth - param_freeze_depth = {network_depth - param_freeze_depth} < layer_depth = {layer_depth} < network_depth = {network_depth}')\n",
    "    if (network_depth - param_freeze_depth) < layer_depth < network_depth:\n",
    "        controlled_layers.append(layer._get_name())\n",
    "#         for param in layer.parameters():\n",
    "#             param.requires_grad = control\n",
    "\n",
    "print(f'\\n Toggle requires_grad = {control}: ', controlled_layers, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4cf4272d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Epoch: 1/200..  Train Loss: 4.580..  Valid Loss: 4.766..  Valid Accuracy: 0.005..  Runtime - 0 mins\n",
      "Epoch: 2/200..  Train Loss: 3.320..  Valid Loss: 5.536..  Valid Accuracy: 0.009..  Runtime - 0 mins\n",
      "Epoch: 3/200..  Train Loss: 1.932..  Valid Loss: 7.291..  Valid Accuracy: 0.011..  Runtime - 1 mins\n",
      "Epoch: 4/200..  Train Loss: 1.644..  Valid Loss: 9.422..  Valid Accuracy: 0.010..  Runtime - 1 mins\n",
      "Epoch: 5/200..  Train Loss: 0.942..  Valid Loss: 11.368..  Valid Accuracy: 0.010..  Runtime - 1 mins\n",
      "Epoch: 6/200..  Train Loss: 0.790..  Valid Loss: 13.156..  Valid Accuracy: 0.012..  Runtime - 1 mins\n",
      "Epoch: 7/200..  Train Loss: 0.762..  Valid Loss: 14.815..  Valid Accuracy: 0.011..  Runtime - 2 mins\n",
      "Epoch: 8/200..  Train Loss: 0.559..  Valid Loss: 16.674..  Valid Accuracy: 0.012..  Runtime - 2 mins\n",
      "Epoch: 9/200..  Train Loss: 0.295..  Valid Loss: 18.404..  Valid Accuracy: 0.011..  Runtime - 2 mins\n",
      "Epoch: 10/200..  Train Loss: 0.250..  Valid Loss: 19.665..  Valid Accuracy: 0.012..  Runtime - 2 mins\n",
      "Epoch: 11/200..  Train Loss: 0.584..  Valid Loss: 20.655..  Valid Accuracy: 0.010..  Runtime - 3 mins\n",
      "Learnrate changed to: 0.002700\n",
      "Epoch: 12/200..  Train Loss: 0.251..  Valid Loss: 20.269..  Valid Accuracy: 0.010..  Runtime - 3 mins\n",
      "Epoch: 13/200..  Train Loss: 1.320..  Valid Loss: 18.323..  Valid Accuracy: 0.006..  Runtime - 3 mins\n",
      "Learnrate changed to: 0.002430\n",
      "Epoch: 14/200..  Train Loss: 0.279..  Valid Loss: 18.190..  Valid Accuracy: 0.010..  Runtime - 3 mins\n",
      "Epoch: 15/200..  Train Loss: 0.687..  Valid Loss: 17.329..  Valid Accuracy: 0.010..  Runtime - 4 mins\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5688/3460108171.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# if argtrain == 'y':\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# if u5_time_limited_input('Check model can overfit small dataset'):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0moverfit_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_hyperparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo1_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_data_loaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'overfit_loader'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mo5_plot_training_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_hyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name_scheme\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_training_history_overfit.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5688/2984355402.py\u001b[0m in \u001b[0;36mo1_train_model\u001b[1;34m(model, dict_data_loaders, epoch, type_loader, criterion)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mave_training_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo2_model_backprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_data_loaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype_loader\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mepoch_count_correct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mave_validate_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo3_model_no_backprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_data_loaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'valid_loader'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mmodel_hyperparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'training_loss_history'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mave_training_loss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# append ave training loss to history of training losses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5688/2984355402.py\u001b[0m in \u001b[0;36mo3_model_no_backprop\u001b[1;34m(model, data_loader, criterion)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# set model to evaluate mode to deactivate generalizing operations such as dropout and leverage full model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# turn off gradient tracking and calculation for computational efficiency\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# cycle through validate data to observe performance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m             \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# move data to GPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m             \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \"\"\"\n\u001b[1;32m--> 297\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mresize\u001b[1;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[0;32m    399\u001b[0m             )\n\u001b[0;32m    400\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[1;34m(img, size, interpolation, max_size)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mnew_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_short\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_long\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mh\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_long\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_short\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmax_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mresize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   2006\u001b[0m                 )\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Record start time\n",
    "start_program_time = time.time()\n",
    "\n",
    "# Get processed data\n",
    "dict_datasets, data_labels_dic = u2_load_processed_data(argdir)\n",
    "dict_data_loaders = u4_data_iterator(dict_datasets)\n",
    "\n",
    "#Create file pathway for hyperparameter saving to JSON format later\n",
    "file_name_scheme = os.path.basename(os.path.dirname(argdir)) + '_' + argmodel\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Download a classifer model for use\n",
    "model = m1_create_classifier(argmodel, len(dict_datasets['train_data'].classes))\n",
    "\n",
    "# if argtrain == 'y':\n",
    "# if u5_time_limited_input('Check model can overfit small dataset'):\n",
    "overfit_model, model_hyperparameters = o1_train_model(model, dict_data_loaders, argepoch, 'overfit_loader', criterion)\n",
    "o5_plot_training_history(argmodel, model_hyperparameters)\n",
    "plt.savefig(file_name_scheme + '_training_history_overfit.png')\n",
    "print('Saved overfit training history to project directory')\n",
    "\n",
    "# if u5_time_limited_input('Continue with complete model training'):\n",
    "#     model, model_hyperparameters = o1_train_model(model, dict_data_loaders, argepoch, 'train_loader', criterion)\n",
    "#     o5_plot_training_history(argmodel, model_hyperparameters)\n",
    "#     plt.savefig(file_name_scheme + '_training_history_complete.png')\n",
    "#     print('Saved complete training history to project directory')\n",
    "\n",
    "#     if u5_time_limited_input('Would you like to test the model'):\n",
    "t1 = time.time()\n",
    "test_count_correct, ave_test_loss = o3_model_no_backprop(model, dict_data_loaders['testing_loader'], criterion)\n",
    "print('testing Loss: {:.3f}.. '.format(ave_test_loss),\n",
    "    'testing Accuracy: {:.3f}'.format(test_count_correct / len(dict_data_loaders['testing_loader'].dataset)),\n",
    "    'Runtime - {:.0f} seconds'.format((time.time() - t1)))\n",
    "\n",
    "#     #Save the model hyperparameters and the locations in which the CNN training activated and deactivated\n",
    "#     if u5_time_limited_input('Would you like to save the model'):\n",
    "#         m2_save_model_checkpoint(model, file_name_scheme, model_hyperparameters)\n",
    "\n",
    "# if argtrain == 'n':\n",
    "#     model, model_hyperparameters = m3_load_model_checkpoint(model, file_name_scheme)\n",
    "#     o5_plot_training_history(argmodel, model_hyperparameters)\n",
    "#     plt.show(block=False)\n",
    "#     plt.pause(3)\n",
    "#     plt.close()\n",
    "\n",
    "#     learnrate = model_hyperparameters['learnrate']\n",
    "#     training_loss_history = model_hyperparameters['training_loss_history']\n",
    "#     validate_loss_history = model_hyperparameters['validate_loss_history']\n",
    "#     epoch_on = model_hyperparameters['epoch_on']\n",
    "#     running_count = model_hyperparameters['running_count']\n",
    "\n",
    "#     print('The model is ready to provide predictions')\n",
    "\n",
    "    #\n",
    "    # o6_predict_data():\n",
    "    #\n",
    "    # u7_show_prediction():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccc3879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
